{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CKD Case Definition 1: ESRD with transplant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "── \u001b[1mAttaching core tidyverse packages\u001b[22m ──────────────────────── tidyverse 2.0.0 ──\n",
      "\u001b[32m✔\u001b[39m \u001b[34mdplyr    \u001b[39m 1.1.4     \u001b[32m✔\u001b[39m \u001b[34mreadr    \u001b[39m 2.1.5\n",
      "\u001b[32m✔\u001b[39m \u001b[34mforcats  \u001b[39m 1.0.0     \u001b[32m✔\u001b[39m \u001b[34mstringr  \u001b[39m 1.5.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mggplot2  \u001b[39m 3.5.2     \u001b[32m✔\u001b[39m \u001b[34mtibble   \u001b[39m 3.2.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mlubridate\u001b[39m 1.9.4     \u001b[32m✔\u001b[39m \u001b[34mtidyr    \u001b[39m 1.3.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mpurrr    \u001b[39m 1.0.4     \n",
      "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "\u001b[36mℹ\u001b[39m Use the conflicted package (\u001b[3m\u001b[34m<http://conflicted.r-lib.org/>\u001b[39m\u001b[23m) to force all conflicts to become errors\n",
      "The data will be written to gs://fc-secure-672eeb92-4859-4ed9-9f59-d4349f3534a0/bq_exports/micah_hysong@researchallofus.org/20250825/condition_93801899/condition_93801899_*.csv. Use this path when reading the data into your notebooks in the future.\n",
      "\n",
      "Loading gs://fc-secure-672eeb92-4859-4ed9-9f59-d4349f3534a0/bq_exports/micah_hysong@researchallofus.org/20250825/condition_93801899/condition_93801899_000000000000.csv.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'Chronic rejection of renal transplant'</li><li>'Renal transplant rejection'</li><li>'Delayed renal graft function'</li><li>'Acute rejection of renal transplant - grade I'</li><li>'Transplant renal artery stenosis'</li><li>'Recurrent post-transplant renal disease'</li><li>'Failed renal transplant'</li><li>'Acute rejection of renal transplant'</li><li>'Transplant glomerulopathy'</li><li>'Transplanted kidney present'</li><li>'Disorder of transplanted kidney'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'Chronic rejection of renal transplant'\n",
       "\\item 'Renal transplant rejection'\n",
       "\\item 'Delayed renal graft function'\n",
       "\\item 'Acute rejection of renal transplant - grade I'\n",
       "\\item 'Transplant renal artery stenosis'\n",
       "\\item 'Recurrent post-transplant renal disease'\n",
       "\\item 'Failed renal transplant'\n",
       "\\item 'Acute rejection of renal transplant'\n",
       "\\item 'Transplant glomerulopathy'\n",
       "\\item 'Transplanted kidney present'\n",
       "\\item 'Disorder of transplanted kidney'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'Chronic rejection of renal transplant'\n",
       "2. 'Renal transplant rejection'\n",
       "3. 'Delayed renal graft function'\n",
       "4. 'Acute rejection of renal transplant - grade I'\n",
       "5. 'Transplant renal artery stenosis'\n",
       "6. 'Recurrent post-transplant renal disease'\n",
       "7. 'Failed renal transplant'\n",
       "8. 'Acute rejection of renal transplant'\n",
       "9. 'Transplant glomerulopathy'\n",
       "10. 'Transplanted kidney present'\n",
       "11. 'Disorder of transplanted kidney'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"Chronic rejection of renal transplant\"        \n",
       " [2] \"Renal transplant rejection\"                   \n",
       " [3] \"Delayed renal graft function\"                 \n",
       " [4] \"Acute rejection of renal transplant - grade I\"\n",
       " [5] \"Transplant renal artery stenosis\"             \n",
       " [6] \"Recurrent post-transplant renal disease\"      \n",
       " [7] \"Failed renal transplant\"                      \n",
       " [8] \"Acute rejection of renal transplant\"          \n",
       " [9] \"Transplant glomerulopathy\"                    \n",
       "[10] \"Transplanted kidney present\"                  \n",
       "[11] \"Disorder of transplanted kidney\"              "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The data will be written to gs://fc-secure-672eeb92-4859-4ed9-9f59-d4349f3534a0/bq_exports/micah_hysong@researchallofus.org/20250825/procedure_93801899/procedure_93801899_*.csv. Use this path when reading the data into your notebooks in the future.\n",
      "\n",
      "Loading gs://fc-secure-672eeb92-4859-4ed9-9f59-d4349f3534a0/bq_exports/micah_hysong@researchallofus.org/20250825/procedure_93801899/procedure_93801899_000000000000.csv.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'Transplant of kidney'</li><li>'Autotransplantation of kidney'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'Transplant of kidney'\n",
       "\\item 'Autotransplantation of kidney'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'Transplant of kidney'\n",
       "2. 'Autotransplantation of kidney'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"Transplant of kidney\"          \"Autotransplantation of kidney\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(tidyverse)\n",
    "library(bigrquery)\n",
    "\n",
    "# This query represents dataset \"kidney_transplant\" for domain \"condition\" and was generated for All of Us Controlled Tier Dataset v7\n",
    "dataset_93801899_condition_sql <- paste(\"\n",
    "    SELECT\n",
    "        c_occurrence.person_id,\n",
    "        c_occurrence.condition_concept_id,\n",
    "        c_standard_concept.concept_name as standard_concept_name,\n",
    "        c_standard_concept.concept_code as standard_concept_code,\n",
    "        c_standard_concept.vocabulary_id as standard_vocabulary \n",
    "    FROM\n",
    "        ( SELECT\n",
    "            * \n",
    "        FROM\n",
    "            `condition_occurrence` c_occurrence \n",
    "        WHERE\n",
    "            (\n",
    "                condition_concept_id IN (SELECT\n",
    "                    DISTINCT c.concept_id \n",
    "                FROM\n",
    "                    `cb_criteria` c \n",
    "                JOIN\n",
    "                    (SELECT\n",
    "                        CAST(cr.id as string) AS id       \n",
    "                    FROM\n",
    "                        `cb_criteria` cr       \n",
    "                    WHERE\n",
    "                        concept_id IN (199991, 42539502)       \n",
    "                        AND full_text LIKE '%_rank1]%'      ) a \n",
    "                        ON (c.path LIKE CONCAT('%.', a.id, '.%') \n",
    "                        OR c.path LIKE CONCAT('%.', a.id) \n",
    "                        OR c.path LIKE CONCAT(a.id, '.%') \n",
    "                        OR c.path = a.id) \n",
    "                WHERE\n",
    "                    is_standard = 1 \n",
    "                    AND is_selectable = 1)\n",
    "            )  \n",
    "            AND (\n",
    "                c_occurrence.PERSON_ID IN (SELECT\n",
    "                    distinct person_id  \n",
    "                FROM\n",
    "                    `cb_search_person` cb_search_person  \n",
    "                WHERE\n",
    "                    cb_search_person.person_id IN (SELECT\n",
    "                        person_id \n",
    "                    FROM\n",
    "                        `cb_search_person` p \n",
    "                    WHERE\n",
    "                        has_whole_genome_variant = 1 ) \n",
    "                    AND cb_search_person.person_id IN (SELECT\n",
    "                        person_id \n",
    "                    FROM\n",
    "                        `cb_search_person` p \n",
    "                    WHERE\n",
    "                        has_ehr_data = 1 ) )\n",
    "            )) c_occurrence \n",
    "    LEFT JOIN\n",
    "        `concept` c_standard_concept \n",
    "            ON c_occurrence.condition_concept_id = c_standard_concept.concept_id\", sep=\"\")\n",
    "\n",
    "# Formulate a Cloud Storage destination path for the data exported from BigQuery.\n",
    "# NOTE: By default data exported multiple times on the same day will overwrite older copies.\n",
    "#       But data exported on a different days will write to a new location so that historical\n",
    "#       copies can be kept as the dataset definition is changed.\n",
    "condition_93801899_path <- file.path(\n",
    "  Sys.getenv(\"WORKSPACE_BUCKET\"),\n",
    "  \"bq_exports\",\n",
    "  Sys.getenv(\"OWNER_EMAIL\"),\n",
    "  strftime(lubridate::now(), \"%Y%m%d\"),  # Comment out this line if you want the export to always overwrite.\n",
    "  \"condition_93801899\",\n",
    "  \"condition_93801899_*.csv\")\n",
    "message(str_glue('The data will be written to {condition_93801899_path}. Use this path when reading ',\n",
    "                 'the data into your notebooks in the future.'))\n",
    "\n",
    "# Perform the query and export the dataset to Cloud Storage as CSV files.\n",
    "# NOTE: You only need to run `bq_table_save` once. After that, you can\n",
    "#       just read data from the CSVs in Cloud Storage.\n",
    "bq_table_save(\n",
    "  bq_dataset_query(Sys.getenv(\"WORKSPACE_CDR\"), dataset_93801899_condition_sql, billing = Sys.getenv(\"GOOGLE_PROJECT\")),\n",
    "  condition_93801899_path,\n",
    "  destination_format = \"CSV\")\n",
    "\n",
    "\n",
    "# Read the data directly from Cloud Storage into memory.\n",
    "# NOTE: Alternatively you can `gsutil -m cp {condition_93801899_path}` to copy these files\n",
    "#       to the Jupyter disk.\n",
    "read_bq_export_from_workspace_bucket <- function(export_path) {\n",
    "  col_types <- cols(standard_concept_name = col_character(), standard_concept_code = col_character(), standard_vocabulary = col_character())\n",
    "  bind_rows(\n",
    "    map(system2('gsutil', args = c('ls', export_path), stdout = TRUE, stderr = TRUE),\n",
    "        function(csv) {\n",
    "          message(str_glue('Loading {csv}.'))\n",
    "          chunk <- read_csv(pipe(str_glue('gsutil cat {csv}')), col_types = col_types, show_col_types = FALSE)\n",
    "          if (is.null(col_types)) {\n",
    "            col_types <- spec(chunk)\n",
    "          }\n",
    "          chunk\n",
    "        }))\n",
    "}\n",
    "kidney_transplant_condition_df <- read_bq_export_from_workspace_bucket(condition_93801899_path)\n",
    "\n",
    "unique(kidney_transplant_condition_df$standard_concept_name)\n",
    "\n",
    "# This query represents dataset \"kidney_transplant\" for domain \"procedure\" and was generated for All of Us Controlled Tier Dataset v7\n",
    "dataset_93801899_procedure_sql <- paste(\"\n",
    "    SELECT\n",
    "        procedure.person_id,\n",
    "        procedure.procedure_concept_id,\n",
    "        p_standard_concept.concept_name as standard_concept_name,\n",
    "        p_standard_concept.concept_code as standard_concept_code,\n",
    "        p_standard_concept.vocabulary_id as standard_vocabulary \n",
    "    FROM\n",
    "        ( SELECT\n",
    "            * \n",
    "        FROM\n",
    "            `procedure_occurrence` procedure \n",
    "        WHERE\n",
    "            (\n",
    "                procedure_concept_id IN (SELECT\n",
    "                    DISTINCT c.concept_id \n",
    "                FROM\n",
    "                    `cb_criteria` c \n",
    "                JOIN\n",
    "                    (SELECT\n",
    "                        CAST(cr.id as string) AS id       \n",
    "                    FROM\n",
    "                        `cb_criteria` cr       \n",
    "                    WHERE\n",
    "                        concept_id IN (4322471)       \n",
    "                        AND full_text LIKE '%_rank1]%'      ) a \n",
    "                        ON (c.path LIKE CONCAT('%.', a.id, '.%') \n",
    "                        OR c.path LIKE CONCAT('%.', a.id) \n",
    "                        OR c.path LIKE CONCAT(a.id, '.%') \n",
    "                        OR c.path = a.id) \n",
    "                WHERE\n",
    "                    is_standard = 1 \n",
    "                    AND is_selectable = 1)\n",
    "            )  \n",
    "            AND (\n",
    "                procedure.PERSON_ID IN (SELECT\n",
    "                    distinct person_id  \n",
    "                FROM\n",
    "                    `cb_search_person` cb_search_person  \n",
    "                WHERE\n",
    "                    cb_search_person.person_id IN (SELECT\n",
    "                        person_id \n",
    "                    FROM\n",
    "                        `cb_search_person` p \n",
    "                    WHERE\n",
    "                        has_whole_genome_variant = 1 ) \n",
    "                    AND cb_search_person.person_id IN (SELECT\n",
    "                        person_id \n",
    "                    FROM\n",
    "                        `cb_search_person` p \n",
    "                    WHERE\n",
    "                        has_ehr_data = 1 ) )\n",
    "            )) procedure \n",
    "    LEFT JOIN\n",
    "        `concept` p_standard_concept \n",
    "            ON procedure.procedure_concept_id = p_standard_concept.concept_id\", sep=\"\")\n",
    "\n",
    "# Formulate a Cloud Storage destination path for the data exported from BigQuery.\n",
    "# NOTE: By default data exported multiple times on the same day will overwrite older copies.\n",
    "#       But data exported on a different days will write to a new location so that historical\n",
    "#       copies can be kept as the dataset definition is changed.\n",
    "procedure_93801899_path <- file.path(\n",
    "  Sys.getenv(\"WORKSPACE_BUCKET\"),\n",
    "  \"bq_exports\",\n",
    "  Sys.getenv(\"OWNER_EMAIL\"),\n",
    "  strftime(lubridate::now(), \"%Y%m%d\"),  # Comment out this line if you want the export to always overwrite.\n",
    "  \"procedure_93801899\",\n",
    "  \"procedure_93801899_*.csv\")\n",
    "message(str_glue('The data will be written to {procedure_93801899_path}. Use this path when reading ',\n",
    "                 'the data into your notebooks in the future.'))\n",
    "\n",
    "# Perform the query and export the dataset to Cloud Storage as CSV files.\n",
    "# NOTE: You only need to run `bq_table_save` once. After that, you can\n",
    "#       just read data from the CSVs in Cloud Storage.\n",
    "bq_table_save(\n",
    "  bq_dataset_query(Sys.getenv(\"WORKSPACE_CDR\"), dataset_93801899_procedure_sql, billing = Sys.getenv(\"GOOGLE_PROJECT\")),\n",
    "  procedure_93801899_path,\n",
    "  destination_format = \"CSV\")\n",
    "\n",
    "\n",
    "# Read the data directly from Cloud Storage into memory.\n",
    "# NOTE: Alternatively you can `gsutil -m cp {procedure_93801899_path}` to copy these files\n",
    "#       to the Jupyter disk.\n",
    "read_bq_export_from_workspace_bucket <- function(export_path) {\n",
    "  col_types <- cols(standard_concept_name = col_character(), standard_concept_code = col_character(), standard_vocabulary = col_character())\n",
    "  bind_rows(\n",
    "    map(system2('gsutil', args = c('ls', export_path), stdout = TRUE, stderr = TRUE),\n",
    "        function(csv) {\n",
    "          message(str_glue('Loading {csv}.'))\n",
    "          chunk <- read_csv(pipe(str_glue('gsutil cat {csv}')), col_types = col_types, show_col_types = FALSE)\n",
    "          if (is.null(col_types)) {\n",
    "            col_types <- spec(chunk)\n",
    "          }\n",
    "          chunk\n",
    "        }))\n",
    "}\n",
    "kidney_transplant_procedure_df <- read_bq_export_from_workspace_bucket(procedure_93801899_path)\n",
    "\n",
    "unique(kidney_transplant_procedure_df$standard_concept_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "2253"
      ],
      "text/latex": [
       "2253"
      ],
      "text/markdown": [
       "2253"
      ],
      "text/plain": [
       "[1] 2253"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kidney_transplant <- unique(c(kidney_transplant_condition_df$person_id, kidney_transplant_procedure_df$person_id))\n",
    "case_definition_1 <- unique(c(kidney_transplant_condition_df$person_id, kidney_transplant_procedure_df$person_id))\n",
    "length(case_definition_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CKD Case Definition 2: ESRD on dialysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The data will be written to gs://fc-secure-672eeb92-4859-4ed9-9f59-d4349f3534a0/bq_exports/micah_hysong@researchallofus.org/20250825/condition_04318565/condition_04318565_*.csv. Use this path when reading the data into your notebooks in the future.\n",
      "\n",
      "Loading gs://fc-secure-672eeb92-4859-4ed9-9f59-d4349f3534a0/bq_exports/micah_hysong@researchallofus.org/20250825/condition_04318565/condition_04318565_000000000000.csv.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'Mechanical complication of dialysis catheter'</li><li>'Infection of hemodialysis arteriovenous fistula'</li><li>'Complication of dialysis'</li><li>'Complication of renal dialysis'</li><li>'Leakage of peritoneal dialysis catheter'</li><li>'Complication associated with dialysis catheter'</li><li>'Infection associated with peritoneal dialysis catheter'</li><li>'Peritoneal dialysis-associated peritonitis'</li><li>'Migration of peritoneal dialysis catheter'</li><li>'Mechanical complication of peritoneal dialysis catheter'</li><li>'Peritoneal dialysis catheter exit site infection'</li><li>'Malfunction of peritoneal dialysis catheter'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'Mechanical complication of dialysis catheter'\n",
       "\\item 'Infection of hemodialysis arteriovenous fistula'\n",
       "\\item 'Complication of dialysis'\n",
       "\\item 'Complication of renal dialysis'\n",
       "\\item 'Leakage of peritoneal dialysis catheter'\n",
       "\\item 'Complication associated with dialysis catheter'\n",
       "\\item 'Infection associated with peritoneal dialysis catheter'\n",
       "\\item 'Peritoneal dialysis-associated peritonitis'\n",
       "\\item 'Migration of peritoneal dialysis catheter'\n",
       "\\item 'Mechanical complication of peritoneal dialysis catheter'\n",
       "\\item 'Peritoneal dialysis catheter exit site infection'\n",
       "\\item 'Malfunction of peritoneal dialysis catheter'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'Mechanical complication of dialysis catheter'\n",
       "2. 'Infection of hemodialysis arteriovenous fistula'\n",
       "3. 'Complication of dialysis'\n",
       "4. 'Complication of renal dialysis'\n",
       "5. 'Leakage of peritoneal dialysis catheter'\n",
       "6. 'Complication associated with dialysis catheter'\n",
       "7. 'Infection associated with peritoneal dialysis catheter'\n",
       "8. 'Peritoneal dialysis-associated peritonitis'\n",
       "9. 'Migration of peritoneal dialysis catheter'\n",
       "10. 'Mechanical complication of peritoneal dialysis catheter'\n",
       "11. 'Peritoneal dialysis catheter exit site infection'\n",
       "12. 'Malfunction of peritoneal dialysis catheter'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"Mechanical complication of dialysis catheter\"           \n",
       " [2] \"Infection of hemodialysis arteriovenous fistula\"        \n",
       " [3] \"Complication of dialysis\"                               \n",
       " [4] \"Complication of renal dialysis\"                         \n",
       " [5] \"Leakage of peritoneal dialysis catheter\"                \n",
       " [6] \"Complication associated with dialysis catheter\"         \n",
       " [7] \"Infection associated with peritoneal dialysis catheter\" \n",
       " [8] \"Peritoneal dialysis-associated peritonitis\"             \n",
       " [9] \"Migration of peritoneal dialysis catheter\"              \n",
       "[10] \"Mechanical complication of peritoneal dialysis catheter\"\n",
       "[11] \"Peritoneal dialysis catheter exit site infection\"       \n",
       "[12] \"Malfunction of peritoneal dialysis catheter\"            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The data will be written to gs://fc-secure-672eeb92-4859-4ed9-9f59-d4349f3534a0/bq_exports/micah_hysong@researchallofus.org/20250825/observation_04318565/observation_04318565_*.csv. Use this path when reading the data into your notebooks in the future.\n",
      "\n",
      "Loading gs://fc-secure-672eeb92-4859-4ed9-9f59-d4349f3534a0/bq_exports/micah_hysong@researchallofus.org/20250825/observation_04318565/observation_04318565_000000000000.csv.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'Dependence on renal dialysis'</li><li>'Non-compliance with renal dialysis'</li><li>'Dialysis finding'</li><li>'Dialysis care'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'Dependence on renal dialysis'\n",
       "\\item 'Non-compliance with renal dialysis'\n",
       "\\item 'Dialysis finding'\n",
       "\\item 'Dialysis care'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'Dependence on renal dialysis'\n",
       "2. 'Non-compliance with renal dialysis'\n",
       "3. 'Dialysis finding'\n",
       "4. 'Dialysis care'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"Dependence on renal dialysis\"       \"Non-compliance with renal dialysis\"\n",
       "[3] \"Dialysis finding\"                   \"Dialysis care\"                     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The data will be written to gs://fc-secure-672eeb92-4859-4ed9-9f59-d4349f3534a0/bq_exports/micah_hysong@researchallofus.org/20250825/procedure_04318565/procedure_04318565_*.csv. Use this path when reading the data into your notebooks in the future.\n",
      "\n",
      "Loading gs://fc-secure-672eeb92-4859-4ed9-9f59-d4349f3534a0/bq_exports/micah_hysong@researchallofus.org/20250825/procedure_04318565/procedure_04318565_000000000000.csv.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'Extracorporeal membrane oxygenation'</li><li>'Peritoneal dialysis'</li><li>'Peritoneal dialysis catheter maintenance'</li><li>'Dialysis procedure'</li><li>'Ultrafiltration'</li><li>'Hemodialysis'</li><li>'Continuous venovenous hemodialysis'</li><li>'Renal dialysis'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'Extracorporeal membrane oxygenation'\n",
       "\\item 'Peritoneal dialysis'\n",
       "\\item 'Peritoneal dialysis catheter maintenance'\n",
       "\\item 'Dialysis procedure'\n",
       "\\item 'Ultrafiltration'\n",
       "\\item 'Hemodialysis'\n",
       "\\item 'Continuous venovenous hemodialysis'\n",
       "\\item 'Renal dialysis'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'Extracorporeal membrane oxygenation'\n",
       "2. 'Peritoneal dialysis'\n",
       "3. 'Peritoneal dialysis catheter maintenance'\n",
       "4. 'Dialysis procedure'\n",
       "5. 'Ultrafiltration'\n",
       "6. 'Hemodialysis'\n",
       "7. 'Continuous venovenous hemodialysis'\n",
       "8. 'Renal dialysis'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"Extracorporeal membrane oxygenation\"     \n",
       "[2] \"Peritoneal dialysis\"                     \n",
       "[3] \"Peritoneal dialysis catheter maintenance\"\n",
       "[4] \"Dialysis procedure\"                      \n",
       "[5] \"Ultrafiltration\"                         \n",
       "[6] \"Hemodialysis\"                            \n",
       "[7] \"Continuous venovenous hemodialysis\"      \n",
       "[8] \"Renal dialysis\"                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(tidyverse)\n",
    "library(bigrquery)\n",
    "\n",
    "# This query represents dataset \"dialysis\" for domain \"condition\" and was generated for All of Us Controlled Tier Dataset v7\n",
    "dataset_04318565_condition_sql <- paste(\"\n",
    "    SELECT\n",
    "        c_occurrence.person_id,\n",
    "        c_occurrence.condition_concept_id,\n",
    "        c_standard_concept.concept_name as standard_concept_name,\n",
    "        c_standard_concept.concept_code as standard_concept_code,\n",
    "        c_standard_concept.vocabulary_id as standard_vocabulary,\n",
    "        c_occurrence.condition_start_datetime \n",
    "    FROM\n",
    "        ( SELECT\n",
    "            * \n",
    "        FROM\n",
    "            `condition_occurrence` c_occurrence \n",
    "        WHERE\n",
    "            (\n",
    "                condition_concept_id IN (SELECT\n",
    "                    DISTINCT c.concept_id \n",
    "                FROM\n",
    "                    `cb_criteria` c \n",
    "                JOIN\n",
    "                    (SELECT\n",
    "                        CAST(cr.id as string) AS id       \n",
    "                    FROM\n",
    "                        `cb_criteria` cr       \n",
    "                    WHERE\n",
    "                        concept_id IN (4027133, 43021247)       \n",
    "                        AND full_text LIKE '%_rank1]%'      ) a \n",
    "                        ON (c.path LIKE CONCAT('%.', a.id, '.%') \n",
    "                        OR c.path LIKE CONCAT('%.', a.id) \n",
    "                        OR c.path LIKE CONCAT(a.id, '.%') \n",
    "                        OR c.path = a.id) \n",
    "                WHERE\n",
    "                    is_standard = 1 \n",
    "                    AND is_selectable = 1)\n",
    "            )  \n",
    "            AND (\n",
    "                c_occurrence.PERSON_ID IN (SELECT\n",
    "                    distinct person_id  \n",
    "                FROM\n",
    "                    `cb_search_person` cb_search_person  \n",
    "                WHERE\n",
    "                    cb_search_person.person_id IN (SELECT\n",
    "                        person_id \n",
    "                    FROM\n",
    "                        `cb_search_person` p \n",
    "                    WHERE\n",
    "                        has_whole_genome_variant = 1 ) \n",
    "                    AND cb_search_person.person_id IN (SELECT\n",
    "                        person_id \n",
    "                    FROM\n",
    "                        `cb_search_person` p \n",
    "                    WHERE\n",
    "                        has_ehr_data = 1 ) )\n",
    "            )) c_occurrence \n",
    "    LEFT JOIN\n",
    "        `concept` c_standard_concept \n",
    "            ON c_occurrence.condition_concept_id = c_standard_concept.concept_id\", sep=\"\")\n",
    "\n",
    "# Formulate a Cloud Storage destination path for the data exported from BigQuery.\n",
    "# NOTE: By default data exported multiple times on the same day will overwrite older copies.\n",
    "#       But data exported on a different days will write to a new location so that historical\n",
    "#       copies can be kept as the dataset definition is changed.\n",
    "condition_04318565_path <- file.path(\n",
    "  Sys.getenv(\"WORKSPACE_BUCKET\"),\n",
    "  \"bq_exports\",\n",
    "  Sys.getenv(\"OWNER_EMAIL\"),\n",
    "  strftime(lubridate::now(), \"%Y%m%d\"),  # Comment out this line if you want the export to always overwrite.\n",
    "  \"condition_04318565\",\n",
    "  \"condition_04318565_*.csv\")\n",
    "message(str_glue('The data will be written to {condition_04318565_path}. Use this path when reading ',\n",
    "                 'the data into your notebooks in the future.'))\n",
    "\n",
    "# Perform the query and export the dataset to Cloud Storage as CSV files.\n",
    "# NOTE: You only need to run `bq_table_save` once. After that, you can\n",
    "#       just read data from the CSVs in Cloud Storage.\n",
    "bq_table_save(\n",
    "  bq_dataset_query(Sys.getenv(\"WORKSPACE_CDR\"), dataset_04318565_condition_sql, billing = Sys.getenv(\"GOOGLE_PROJECT\")),\n",
    "  condition_04318565_path,\n",
    "  destination_format = \"CSV\")\n",
    "\n",
    "\n",
    "# Read the data directly from Cloud Storage into memory.\n",
    "# NOTE: Alternatively you can `gsutil -m cp {condition_04318565_path}` to copy these files\n",
    "#       to the Jupyter disk.\n",
    "read_bq_export_from_workspace_bucket <- function(export_path) {\n",
    "  col_types <- cols(standard_concept_name = col_character(), standard_concept_code = col_character(), standard_vocabulary = col_character())\n",
    "  bind_rows(\n",
    "    map(system2('gsutil', args = c('ls', export_path), stdout = TRUE, stderr = TRUE),\n",
    "        function(csv) {\n",
    "          message(str_glue('Loading {csv}.'))\n",
    "          chunk <- read_csv(pipe(str_glue('gsutil cat {csv}')), col_types = col_types, show_col_types = FALSE)\n",
    "          if (is.null(col_types)) {\n",
    "            col_types <- spec(chunk)\n",
    "          }\n",
    "          chunk\n",
    "        }))\n",
    "}\n",
    "dialysis_condition_df <- read_bq_export_from_workspace_bucket(condition_04318565_path)\n",
    "unique(dialysis_condition_df$standard_concept_name)\n",
    "\n",
    "# This query represents dataset \"dialysis\" for domain \"observation\" and was generated for All of Us Controlled Tier Dataset v7\n",
    "dataset_04318565_observation_sql <- paste(\"\n",
    "    SELECT\n",
    "        observation.person_id,\n",
    "        observation.observation_concept_id,\n",
    "        o_standard_concept.concept_name as standard_concept_name,\n",
    "        o_standard_concept.concept_code as standard_concept_code,\n",
    "        o_standard_concept.vocabulary_id as standard_vocabulary,\n",
    "        observation.observation_datetime \n",
    "    FROM\n",
    "        ( SELECT\n",
    "            * \n",
    "        FROM\n",
    "            `observation` observation \n",
    "        WHERE\n",
    "            (\n",
    "                observation_concept_id IN (4019967, 4059475, 4090651, 4301680, 46270032)\n",
    "            )  \n",
    "            AND (\n",
    "                observation.PERSON_ID IN (SELECT\n",
    "                    distinct person_id  \n",
    "                FROM\n",
    "                    `cb_search_person` cb_search_person  \n",
    "                WHERE\n",
    "                    cb_search_person.person_id IN (SELECT\n",
    "                        person_id \n",
    "                    FROM\n",
    "                        `cb_search_person` p \n",
    "                    WHERE\n",
    "                        has_whole_genome_variant = 1 ) \n",
    "                    AND cb_search_person.person_id IN (SELECT\n",
    "                        person_id \n",
    "                    FROM\n",
    "                        `cb_search_person` p \n",
    "                    WHERE\n",
    "                        has_ehr_data = 1 ) )\n",
    "            )) observation \n",
    "    LEFT JOIN\n",
    "        `concept` o_standard_concept \n",
    "            ON observation.observation_concept_id = o_standard_concept.concept_id\", sep=\"\")\n",
    "\n",
    "# Formulate a Cloud Storage destination path for the data exported from BigQuery.\n",
    "# NOTE: By default data exported multiple times on the same day will overwrite older copies.\n",
    "#       But data exported on a different days will write to a new location so that historical\n",
    "#       copies can be kept as the dataset definition is changed.\n",
    "observation_04318565_path <- file.path(\n",
    "  Sys.getenv(\"WORKSPACE_BUCKET\"),\n",
    "  \"bq_exports\",\n",
    "  Sys.getenv(\"OWNER_EMAIL\"),\n",
    "  strftime(lubridate::now(), \"%Y%m%d\"),  # Comment out this line if you want the export to always overwrite.\n",
    "  \"observation_04318565\",\n",
    "  \"observation_04318565_*.csv\")\n",
    "message(str_glue('The data will be written to {observation_04318565_path}. Use this path when reading ',\n",
    "                 'the data into your notebooks in the future.'))\n",
    "\n",
    "# Perform the query and export the dataset to Cloud Storage as CSV files.\n",
    "# NOTE: You only need to run `bq_table_save` once. After that, you can\n",
    "#       just read data from the CSVs in Cloud Storage.\n",
    "bq_table_save(\n",
    "  bq_dataset_query(Sys.getenv(\"WORKSPACE_CDR\"), dataset_04318565_observation_sql, billing = Sys.getenv(\"GOOGLE_PROJECT\")),\n",
    "  observation_04318565_path,\n",
    "  destination_format = \"CSV\")\n",
    "\n",
    "\n",
    "# Read the data directly from Cloud Storage into memory.\n",
    "# NOTE: Alternatively you can `gsutil -m cp {observation_04318565_path}` to copy these files\n",
    "#       to the Jupyter disk.\n",
    "read_bq_export_from_workspace_bucket <- function(export_path) {\n",
    "  col_types <- cols(standard_concept_name = col_character(), standard_concept_code = col_character(), standard_vocabulary = col_character())\n",
    "  bind_rows(\n",
    "    map(system2('gsutil', args = c('ls', export_path), stdout = TRUE, stderr = TRUE),\n",
    "        function(csv) {\n",
    "          message(str_glue('Loading {csv}.'))\n",
    "          chunk <- read_csv(pipe(str_glue('gsutil cat {csv}')), col_types = col_types, show_col_types = FALSE)\n",
    "          if (is.null(col_types)) {\n",
    "            col_types <- spec(chunk)\n",
    "          }\n",
    "          chunk\n",
    "        }))\n",
    "}\n",
    "dialysis_observation_df <- read_bq_export_from_workspace_bucket(observation_04318565_path)\n",
    "unique(dialysis_observation_df$standard_concept_name)\n",
    "\n",
    "# This query represents dataset \"dialysis\" for domain \"procedure\" and was generated for All of Us Controlled Tier Dataset v7\n",
    "dataset_04318565_procedure_sql <- paste(\"\n",
    "    SELECT\n",
    "        procedure.person_id,\n",
    "        procedure.procedure_concept_id,\n",
    "        p_standard_concept.concept_name as standard_concept_name,\n",
    "        p_standard_concept.concept_code as standard_concept_code,\n",
    "        p_standard_concept.vocabulary_id as standard_vocabulary,\n",
    "        procedure.procedure_datetime \n",
    "    FROM\n",
    "        ( SELECT\n",
    "            * \n",
    "        FROM\n",
    "            `procedure_occurrence` procedure \n",
    "        WHERE\n",
    "            (\n",
    "                procedure_concept_id IN (SELECT\n",
    "                    DISTINCT c.concept_id \n",
    "                FROM\n",
    "                    `cb_criteria` c \n",
    "                JOIN\n",
    "                    (SELECT\n",
    "                        CAST(cr.id as string) AS id       \n",
    "                    FROM\n",
    "                        `cb_criteria` cr       \n",
    "                    WHERE\n",
    "                        concept_id IN (4032243)       \n",
    "                        AND full_text LIKE '%_rank1]%'      ) a \n",
    "                        ON (c.path LIKE CONCAT('%.', a.id, '.%') \n",
    "                        OR c.path LIKE CONCAT('%.', a.id) \n",
    "                        OR c.path LIKE CONCAT(a.id, '.%') \n",
    "                        OR c.path = a.id) \n",
    "                WHERE\n",
    "                    is_standard = 1 \n",
    "                    AND is_selectable = 1)\n",
    "            )  \n",
    "            AND (\n",
    "                procedure.PERSON_ID IN (SELECT\n",
    "                    distinct person_id  \n",
    "                FROM\n",
    "                    `cb_search_person` cb_search_person  \n",
    "                WHERE\n",
    "                    cb_search_person.person_id IN (SELECT\n",
    "                        person_id \n",
    "                    FROM\n",
    "                        `cb_search_person` p \n",
    "                    WHERE\n",
    "                        has_whole_genome_variant = 1 ) \n",
    "                    AND cb_search_person.person_id IN (SELECT\n",
    "                        person_id \n",
    "                    FROM\n",
    "                        `cb_search_person` p \n",
    "                    WHERE\n",
    "                        has_ehr_data = 1 ) )\n",
    "            )) procedure \n",
    "    LEFT JOIN\n",
    "        `concept` p_standard_concept \n",
    "            ON procedure.procedure_concept_id = p_standard_concept.concept_id\", sep=\"\")\n",
    "\n",
    "# Formulate a Cloud Storage destination path for the data exported from BigQuery.\n",
    "# NOTE: By default data exported multiple times on the same day will overwrite older copies.\n",
    "#       But data exported on a different days will write to a new location so that historical\n",
    "#       copies can be kept as the dataset definition is changed.\n",
    "procedure_04318565_path <- file.path(\n",
    "  Sys.getenv(\"WORKSPACE_BUCKET\"),\n",
    "  \"bq_exports\",\n",
    "  Sys.getenv(\"OWNER_EMAIL\"),\n",
    "  strftime(lubridate::now(), \"%Y%m%d\"),  # Comment out this line if you want the export to always overwrite.\n",
    "  \"procedure_04318565\",\n",
    "  \"procedure_04318565_*.csv\")\n",
    "message(str_glue('The data will be written to {procedure_04318565_path}. Use this path when reading ',\n",
    "                 'the data into your notebooks in the future.'))\n",
    "\n",
    "# Perform the query and export the dataset to Cloud Storage as CSV files.\n",
    "# NOTE: You only need to run `bq_table_save` once. After that, you can\n",
    "#       just read data from the CSVs in Cloud Storage.\n",
    "bq_table_save(\n",
    "  bq_dataset_query(Sys.getenv(\"WORKSPACE_CDR\"), dataset_04318565_procedure_sql, billing = Sys.getenv(\"GOOGLE_PROJECT\")),\n",
    "  procedure_04318565_path,\n",
    "  destination_format = \"CSV\")\n",
    "\n",
    "\n",
    "# Read the data directly from Cloud Storage into memory.\n",
    "# NOTE: Alternatively you can `gsutil -m cp {procedure_04318565_path}` to copy these files\n",
    "#       to the Jupyter disk.\n",
    "read_bq_export_from_workspace_bucket <- function(export_path) {\n",
    "  col_types <- cols(standard_concept_name = col_character(), standard_concept_code = col_character(), standard_vocabulary = col_character())\n",
    "  bind_rows(\n",
    "    map(system2('gsutil', args = c('ls', export_path), stdout = TRUE, stderr = TRUE),\n",
    "        function(csv) {\n",
    "          message(str_glue('Loading {csv}.'))\n",
    "          chunk <- read_csv(pipe(str_glue('gsutil cat {csv}')), col_types = col_types, show_col_types = FALSE)\n",
    "          if (is.null(col_types)) {\n",
    "            col_types <- spec(chunk)\n",
    "          }\n",
    "          chunk\n",
    "        }))\n",
    "}\n",
    "dialysis_procedure_df <- read_bq_export_from_workspace_bucket(procedure_04318565_path)\n",
    "unique(dialysis_procedure_df$standard_concept_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "names(dialysis_condition_df) <- c(\"person_id\", \"concept_id\", \"standard_concept_name\", \"standard_concept_code\",\n",
    "                                \"standard_vocaabulary\", \"date_time\")\n",
    "names(dialysis_observation_df) <- c(\"person_id\", \"concept_id\", \"standard_concept_name\", \"standard_concept_code\",\n",
    "                                \"standard_vocaabulary\", \"date_time\")\n",
    "names(dialysis_procedure_df) <- c(\"person_id\", \"concept_id\", \"standard_concept_name\", \"standard_concept_code\",\n",
    "                                \"standard_vocaabulary\", \"date_time\")\n",
    "dialysis_1 <- rbind(dialysis_condition_df, dialysis_observation_df)\n",
    "dialysis <- rbind(dialysis_1, dialysis_procedure_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The data will be written to gs://fc-secure-672eeb92-4859-4ed9-9f59-d4349f3534a0/bq_exports/micah_hysong@researchallofus.org/20250825/condition_99489694/condition_99489694_*.csv. Use this path when reading the data into your notebooks in the future.\n",
      "\n",
      "Loading gs://fc-secure-672eeb92-4859-4ed9-9f59-d4349f3534a0/bq_exports/micah_hysong@researchallofus.org/20250825/condition_99489694/condition_99489694_000000000000.csv.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'Acute kidney injury due to circulatory failure'</li><li>'Crush syndrome'</li><li>'Hepatorenal syndrome due to a procedure'</li><li>'Acute kidney injury due to sepsis'</li><li>'Post-delivery acute renal failure with postnatal problem'</li><li>'Acute renal failure due to acute cortical necrosis'</li><li>'Postpartum acute renal failure'</li><li>'Acute renal failure syndrome'</li><li>'Acute renal failure caused by contrast agent'</li><li>'Acute renal papillary necrosis with renal failure'</li><li>'Hepatorenal syndrome'</li><li>'Acute-on-chronic renal failure'</li><li>'Acute nontraumatic kidney injury'</li><li>'Acute kidney failure stage 3'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'Acute kidney injury due to circulatory failure'\n",
       "\\item 'Crush syndrome'\n",
       "\\item 'Hepatorenal syndrome due to a procedure'\n",
       "\\item 'Acute kidney injury due to sepsis'\n",
       "\\item 'Post-delivery acute renal failure with postnatal problem'\n",
       "\\item 'Acute renal failure due to acute cortical necrosis'\n",
       "\\item 'Postpartum acute renal failure'\n",
       "\\item 'Acute renal failure syndrome'\n",
       "\\item 'Acute renal failure caused by contrast agent'\n",
       "\\item 'Acute renal papillary necrosis with renal failure'\n",
       "\\item 'Hepatorenal syndrome'\n",
       "\\item 'Acute-on-chronic renal failure'\n",
       "\\item 'Acute nontraumatic kidney injury'\n",
       "\\item 'Acute kidney failure stage 3'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'Acute kidney injury due to circulatory failure'\n",
       "2. 'Crush syndrome'\n",
       "3. 'Hepatorenal syndrome due to a procedure'\n",
       "4. 'Acute kidney injury due to sepsis'\n",
       "5. 'Post-delivery acute renal failure with postnatal problem'\n",
       "6. 'Acute renal failure due to acute cortical necrosis'\n",
       "7. 'Postpartum acute renal failure'\n",
       "8. 'Acute renal failure syndrome'\n",
       "9. 'Acute renal failure caused by contrast agent'\n",
       "10. 'Acute renal papillary necrosis with renal failure'\n",
       "11. 'Hepatorenal syndrome'\n",
       "12. 'Acute-on-chronic renal failure'\n",
       "13. 'Acute nontraumatic kidney injury'\n",
       "14. 'Acute kidney failure stage 3'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"Acute kidney injury due to circulatory failure\"          \n",
       " [2] \"Crush syndrome\"                                          \n",
       " [3] \"Hepatorenal syndrome due to a procedure\"                 \n",
       " [4] \"Acute kidney injury due to sepsis\"                       \n",
       " [5] \"Post-delivery acute renal failure with postnatal problem\"\n",
       " [6] \"Acute renal failure due to acute cortical necrosis\"      \n",
       " [7] \"Postpartum acute renal failure\"                          \n",
       " [8] \"Acute renal failure syndrome\"                            \n",
       " [9] \"Acute renal failure caused by contrast agent\"            \n",
       "[10] \"Acute renal papillary necrosis with renal failure\"       \n",
       "[11] \"Hepatorenal syndrome\"                                    \n",
       "[12] \"Acute-on-chronic renal failure\"                          \n",
       "[13] \"Acute nontraumatic kidney injury\"                        \n",
       "[14] \"Acute kidney failure stage 3\"                            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(tidyverse)\n",
    "library(bigrquery)\n",
    "\n",
    "# This query represents dataset \"acute_kidney\" for domain \"condition\" and was generated for All of Us Controlled Tier Dataset v7\n",
    "dataset_99489694_condition_sql <- paste(\"\n",
    "    SELECT\n",
    "        c_occurrence.person_id,\n",
    "        c_occurrence.condition_concept_id,\n",
    "        c_standard_concept.concept_name as standard_concept_name,\n",
    "        c_standard_concept.concept_code as standard_concept_code,\n",
    "        c_standard_concept.vocabulary_id as standard_vocabulary,\n",
    "        c_occurrence.condition_start_datetime \n",
    "    FROM\n",
    "        ( SELECT\n",
    "            * \n",
    "        FROM\n",
    "            `condition_occurrence` c_occurrence \n",
    "        WHERE\n",
    "            (\n",
    "                condition_concept_id IN (SELECT\n",
    "                    DISTINCT c.concept_id \n",
    "                FROM\n",
    "                    `cb_criteria` c \n",
    "                JOIN\n",
    "                    (SELECT\n",
    "                        CAST(cr.id as string) AS id       \n",
    "                    FROM\n",
    "                        `cb_criteria` cr       \n",
    "                    WHERE\n",
    "                        concept_id IN (197320)       \n",
    "                        AND full_text LIKE '%_rank1]%'      ) a \n",
    "                        ON (c.path LIKE CONCAT('%.', a.id, '.%') \n",
    "                        OR c.path LIKE CONCAT('%.', a.id) \n",
    "                        OR c.path LIKE CONCAT(a.id, '.%') \n",
    "                        OR c.path = a.id) \n",
    "                WHERE\n",
    "                    is_standard = 1 \n",
    "                    AND is_selectable = 1)\n",
    "            )  \n",
    "            AND (\n",
    "                c_occurrence.PERSON_ID IN (SELECT\n",
    "                    distinct person_id  \n",
    "                FROM\n",
    "                    `cb_search_person` cb_search_person  \n",
    "                WHERE\n",
    "                    cb_search_person.person_id IN (SELECT\n",
    "                        person_id \n",
    "                    FROM\n",
    "                        `cb_search_person` p \n",
    "                    WHERE\n",
    "                        has_whole_genome_variant = 1 ) \n",
    "                    AND cb_search_person.person_id IN (SELECT\n",
    "                        person_id \n",
    "                    FROM\n",
    "                        `cb_search_person` p \n",
    "                    WHERE\n",
    "                        has_ehr_data = 1 ) )\n",
    "            )) c_occurrence \n",
    "    LEFT JOIN\n",
    "        `concept` c_standard_concept \n",
    "            ON c_occurrence.condition_concept_id = c_standard_concept.concept_id\", sep=\"\")\n",
    "\n",
    "# Formulate a Cloud Storage destination path for the data exported from BigQuery.\n",
    "# NOTE: By default data exported multiple times on the same day will overwrite older copies.\n",
    "#       But data exported on a different days will write to a new location so that historical\n",
    "#       copies can be kept as the dataset definition is changed.\n",
    "condition_99489694_path <- file.path(\n",
    "  Sys.getenv(\"WORKSPACE_BUCKET\"),\n",
    "  \"bq_exports\",\n",
    "  Sys.getenv(\"OWNER_EMAIL\"),\n",
    "  strftime(lubridate::now(), \"%Y%m%d\"),  # Comment out this line if you want the export to always overwrite.\n",
    "  \"condition_99489694\",\n",
    "  \"condition_99489694_*.csv\")\n",
    "message(str_glue('The data will be written to {condition_99489694_path}. Use this path when reading ',\n",
    "                 'the data into your notebooks in the future.'))\n",
    "\n",
    "# Perform the query and export the dataset to Cloud Storage as CSV files.\n",
    "# NOTE: You only need to run `bq_table_save` once. After that, you can\n",
    "#       just read data from the CSVs in Cloud Storage.\n",
    "bq_table_save(\n",
    "  bq_dataset_query(Sys.getenv(\"WORKSPACE_CDR\"), dataset_99489694_condition_sql, billing = Sys.getenv(\"GOOGLE_PROJECT\")),\n",
    "  condition_99489694_path,\n",
    "  destination_format = \"CSV\")\n",
    "\n",
    "\n",
    "# Read the data directly from Cloud Storage into memory.\n",
    "# NOTE: Alternatively you can `gsutil -m cp {condition_99489694_path}` to copy these files\n",
    "#       to the Jupyter disk.\n",
    "read_bq_export_from_workspace_bucket <- function(export_path) {\n",
    "  col_types <- cols(standard_concept_name = col_character(), standard_concept_code = col_character(), standard_vocabulary = col_character())\n",
    "  bind_rows(\n",
    "    map(system2('gsutil', args = c('ls', export_path), stdout = TRUE, stderr = TRUE),\n",
    "        function(csv) {\n",
    "          message(str_glue('Loading {csv}.'))\n",
    "          chunk <- read_csv(pipe(str_glue('gsutil cat {csv}')), col_types = col_types, show_col_types = FALSE)\n",
    "          if (is.null(col_types)) {\n",
    "            col_types <- spec(chunk)\n",
    "          }\n",
    "          chunk\n",
    "        }))\n",
    "}\n",
    "acute_kidney_df <- read_bq_export_from_workspace_bucket(condition_99489694_path)\n",
    "unique(acute_kidney_df$standard_concept_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove cases of dialysis that occur within one month of Acute Kidney injury \n",
    "library(lubridate)\n",
    "# Calculate the date range for filtering\n",
    "dialysis$date_time <- as.POSIXct(dialysis$date_time)\n",
    "acute_kidney_df$condition_start_datetime <- as.POSIXct(acute_kidney_df$condition_start_datetime)\n",
    "\n",
    "dialysis <- dialysis %>%\n",
    "  mutate(\n",
    "    lower_bound = date_time - months(1),\n",
    "    upper_bound = date_time + months(1)\n",
    "  )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a cross join and filter\n",
    "rows_to_remove <- acute_kidney_df %>%\n",
    "  inner_join(dialysis, by = \"person_id\", relationship = \"many-to-many\") %>%\n",
    "  filter(condition_start_datetime >= lower_bound & condition_start_datetime <= upper_bound) %>%\n",
    "  select(person_id, date_time) %>%\n",
    "  distinct()\n",
    "\n",
    "# Remove the identified rows from the dialysis dataframe\n",
    "dialysis_cleaned <- dialysis %>%\n",
    "  anti_join(rows_to_remove, by = c(\"person_id\", \"date_time\"))\n",
    "\n",
    "dialysis_cleaned <- dialysis_cleaned %>% distinct(person_id, .keep_all = TRUE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "70158"
      ],
      "text/latex": [
       "70158"
      ],
      "text/markdown": [
       "70158"
      ],
      "text/plain": [
       "[1] 70158"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "2777"
      ],
      "text/latex": [
       "2777"
      ],
      "text/markdown": [
       "2777"
      ],
      "text/plain": [
       "[1] 2777"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nrow(dialysis)\n",
    "nrow(dialysis_cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialysis<-dialysis_cleaned\n",
    "case_definition_2<-dialysis_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CKD Case Definition 3: NKF CKD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The data will be written to gs://fc-secure-672eeb92-4859-4ed9-9f59-d4349f3534a0/bq_exports/micah_hysong@researchallofus.org/20250825/measurement_60313913/measurement_60313913_*.csv. Use this path when reading the data into your notebooks in the future.\n",
      "\n",
      "Loading gs://fc-secure-672eeb92-4859-4ed9-9f59-d4349f3534a0/bq_exports/micah_hysong@researchallofus.org/20250825/measurement_60313913/measurement_60313913_000000000000.csv.\n",
      "\n",
      "Loading gs://fc-secure-672eeb92-4859-4ed9-9f59-d4349f3534a0/bq_exports/micah_hysong@researchallofus.org/20250825/measurement_60313913/measurement_60313913_000000000001.csv.\n",
      "\n",
      "Loading gs://fc-secure-672eeb92-4859-4ed9-9f59-d4349f3534a0/bq_exports/micah_hysong@researchallofus.org/20250825/measurement_60313913/measurement_60313913_000000000002.csv.\n",
      "\n",
      "Loading gs://fc-secure-672eeb92-4859-4ed9-9f59-d4349f3534a0/bq_exports/micah_hysong@researchallofus.org/20250825/measurement_60313913/measurement_60313913_000000000003.csv.\n",
      "\n",
      "Loading gs://fc-secure-672eeb92-4859-4ed9-9f59-d4349f3534a0/bq_exports/micah_hysong@researchallofus.org/20250825/measurement_60313913/measurement_60313913_000000000004.csv.\n",
      "\n",
      "Loading gs://fc-secure-672eeb92-4859-4ed9-9f59-d4349f3534a0/bq_exports/micah_hysong@researchallofus.org/20250825/measurement_60313913/measurement_60313913_000000000005.csv.\n",
      "\n",
      "Loading gs://fc-secure-672eeb92-4859-4ed9-9f59-d4349f3534a0/bq_exports/micah_hysong@researchallofus.org/20250825/measurement_60313913/measurement_60313913_000000000006.csv.\n",
      "\n",
      "Loading gs://fc-secure-672eeb92-4859-4ed9-9f59-d4349f3534a0/bq_exports/micah_hysong@researchallofus.org/20250825/measurement_60313913/measurement_60313913_000000000007.csv.\n",
      "\n",
      "Loading gs://fc-secure-672eeb92-4859-4ed9-9f59-d4349f3534a0/bq_exports/micah_hysong@researchallofus.org/20250825/measurement_60313913/measurement_60313913_000000000008.csv.\n",
      "\n",
      "Loading gs://fc-secure-672eeb92-4859-4ed9-9f59-d4349f3534a0/bq_exports/micah_hysong@researchallofus.org/20250825/measurement_60313913/measurement_60313913_000000000009.csv.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "'Creatinine [Mass/volume] in Serum or Plasma'"
      ],
      "text/latex": [
       "'Creatinine {[}Mass/volume{]} in Serum or Plasma'"
      ],
      "text/markdown": [
       "'Creatinine [Mass/volume] in Serum or Plasma'"
      ],
      "text/plain": [
       "[1] \"Creatinine [Mass/volume] in Serum or Plasma\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(tidyverse)\n",
    "library(bigrquery)\n",
    "\n",
    "# This query represents dataset \"Creatinine\" for domain \"measurement\" and was generated for All of Us Controlled Tier Dataset v7\n",
    "dataset_60313913_measurement_sql <- paste(\"\n",
    "    SELECT\n",
    "        measurement.person_id,\n",
    "        measurement.measurement_concept_id,\n",
    "        m_standard_concept.concept_name as standard_concept_name,\n",
    "        m_standard_concept.concept_code as standard_concept_code,\n",
    "        m_standard_concept.vocabulary_id as standard_vocabulary,\n",
    "        measurement.measurement_datetime,\n",
    "        measurement.measurement_type_concept_id,\n",
    "        m_type.concept_name as measurement_type_concept_name,\n",
    "        measurement.operator_concept_id,\n",
    "        m_operator.concept_name as operator_concept_name,\n",
    "        measurement.value_as_number,\n",
    "        measurement.value_as_concept_id,\n",
    "        m_value.concept_name as value_as_concept_name,\n",
    "        measurement.unit_concept_id,\n",
    "        m_unit.concept_name as unit_concept_name,\n",
    "        measurement.range_low,\n",
    "        measurement.range_high,\n",
    "        measurement.visit_occurrence_id,\n",
    "        m_visit.concept_name as visit_occurrence_concept_name,\n",
    "        measurement.measurement_source_value,\n",
    "        measurement.measurement_source_concept_id,\n",
    "        m_source_concept.concept_name as source_concept_name,\n",
    "        m_source_concept.concept_code as source_concept_code,\n",
    "        m_source_concept.vocabulary_id as source_vocabulary,\n",
    "        measurement.unit_source_value,\n",
    "        measurement.value_source_value \n",
    "    FROM\n",
    "        ( SELECT\n",
    "            * \n",
    "        FROM\n",
    "            `measurement` measurement \n",
    "        WHERE\n",
    "            (\n",
    "                measurement_concept_id IN (\n",
    "                    SELECT\n",
    "                        DISTINCT c.concept_id \n",
    "                    FROM\n",
    "                        `cb_criteria` c \n",
    "                    JOIN\n",
    "                        (\n",
    "                            SELECT\n",
    "                                CAST(cr.id as string) AS id       \n",
    "                            FROM\n",
    "                                `cb_criteria` cr       \n",
    "                            WHERE\n",
    "                                concept_id IN (\n",
    "                                    37029387\n",
    "                                )       \n",
    "                                AND full_text LIKE '%_rank1]%'      \n",
    "                        ) a \n",
    "                            ON (\n",
    "                                c.path LIKE CONCAT('%.',\n",
    "                            a.id,\n",
    "                            '.%') \n",
    "                            OR c.path LIKE CONCAT('%.',\n",
    "                            a.id) \n",
    "                            OR c.path LIKE CONCAT(a.id,\n",
    "                            '.%') \n",
    "                            OR c.path = a.id) \n",
    "                        WHERE\n",
    "                            is_standard = 1 \n",
    "                            AND is_selectable = 1\n",
    "                        )\n",
    "                )  \n",
    "                AND (\n",
    "                    measurement.PERSON_ID IN (\n",
    "                        SELECT\n",
    "                            distinct person_id  \n",
    "                        FROM\n",
    "                            `cb_search_person` cb_search_person  \n",
    "                        WHERE\n",
    "                            cb_search_person.person_id IN (\n",
    "                                SELECT\n",
    "                                    person_id \n",
    "                                FROM\n",
    "                                    `cb_search_person` p \n",
    "                                WHERE\n",
    "                                    has_whole_genome_variant = 1 \n",
    "                            ) \n",
    "                            AND cb_search_person.person_id IN (\n",
    "                                SELECT\n",
    "                                    person_id \n",
    "                                FROM\n",
    "                                    `cb_search_person` p \n",
    "                                WHERE\n",
    "                                    has_ehr_data = 1 \n",
    "                            ) \n",
    "                        )\n",
    "                    )\n",
    "            ) measurement \n",
    "        LEFT JOIN\n",
    "            `concept` m_standard_concept \n",
    "                ON measurement.measurement_concept_id = m_standard_concept.concept_id \n",
    "        LEFT JOIN\n",
    "            `concept` m_type \n",
    "                ON measurement.measurement_type_concept_id = m_type.concept_id \n",
    "        LEFT JOIN\n",
    "            `concept` m_operator \n",
    "                ON measurement.operator_concept_id = m_operator.concept_id \n",
    "        LEFT JOIN\n",
    "            `concept` m_value \n",
    "                ON measurement.value_as_concept_id = m_value.concept_id \n",
    "        LEFT JOIN\n",
    "            `concept` m_unit \n",
    "                ON measurement.unit_concept_id = m_unit.concept_id \n",
    "        LEFT JOIn\n",
    "            `visit_occurrence` v \n",
    "                ON measurement.visit_occurrence_id = v.visit_occurrence_id \n",
    "        LEFT JOIN\n",
    "            `concept` m_visit \n",
    "                ON v.visit_concept_id = m_visit.concept_id \n",
    "        LEFT JOIN\n",
    "            `concept` m_source_concept \n",
    "                ON measurement.measurement_source_concept_id = m_source_concept.concept_id\", sep=\"\")\n",
    "\n",
    "# Formulate a Cloud Storage destination path for the data exported from BigQuery.\n",
    "# NOTE: By default data exported multiple times on the same day will overwrite older copies.\n",
    "#       But data exported on a different days will write to a new location so that historical\n",
    "#       copies can be kept as the dataset definition is changed.\n",
    "measurement_60313913_path <- file.path(\n",
    "  Sys.getenv(\"WORKSPACE_BUCKET\"),\n",
    "  \"bq_exports\",\n",
    "  Sys.getenv(\"OWNER_EMAIL\"),\n",
    "  strftime(lubridate::now(), \"%Y%m%d\"),  # Comment out this line if you want the export to always overwrite.\n",
    "  \"measurement_60313913\",\n",
    "  \"measurement_60313913_*.csv\")\n",
    "message(str_glue('The data will be written to {measurement_60313913_path}. Use this path when reading ',\n",
    "                 'the data into your notebooks in the future.'))\n",
    "\n",
    "# Perform the query and export the dataset to Cloud Storage as CSV files.\n",
    "# NOTE: You only need to run `bq_table_save` once. After that, you can\n",
    "#       just read data from the CSVs in Cloud Storage.\n",
    "bq_table_save(\n",
    "  bq_dataset_query(Sys.getenv(\"WORKSPACE_CDR\"), dataset_60313913_measurement_sql, billing = Sys.getenv(\"GOOGLE_PROJECT\")),\n",
    "  measurement_60313913_path,\n",
    "  destination_format = \"CSV\")\n",
    "\n",
    "# Read the data directly from Cloud Storage into memory.\n",
    "# NOTE: Alternatively you can `gsutil -m cp {measurement_60313913_path}` to copy these files\n",
    "#       to the Jupyter disk.\n",
    "read_bq_export_from_workspace_bucket <- function(export_path) {\n",
    "  col_types <- cols(standard_concept_name = col_character(), standard_concept_code = col_character(), standard_vocabulary = col_character(), measurement_type_concept_name = col_character(), operator_concept_name = col_character(), value_as_concept_name = col_character(), unit_concept_name = col_character(), visit_occurrence_concept_name = col_character(), measurement_source_value = col_character(), source_concept_name = col_character(), source_concept_code = col_character(), source_vocabulary = col_character(), unit_source_value = col_character(), value_source_value = col_character())\n",
    "  bind_rows(\n",
    "    map(system2('gsutil', args = c('ls', export_path), stdout = TRUE, stderr = TRUE),\n",
    "        function(csv) {\n",
    "          message(str_glue('Loading {csv}.'))\n",
    "          chunk <- read_csv(pipe(str_glue('gsutil cat {csv}')), col_types = col_types, show_col_types = FALSE)\n",
    "          if (is.null(col_types)) {\n",
    "            col_types <- spec(chunk)\n",
    "          }\n",
    "          chunk\n",
    "        }))\n",
    "}\n",
    "measurement_df <- read_bq_export_from_workspace_bucket(measurement_60313913_path)\n",
    "\n",
    "measurement_df <- measurement_df %>%\n",
    "                filter(unit_source_value == 258797006 | unit_source_value == \"mg/dL\") |>\n",
    "                      filter(standard_concept_name == \"Creatinine [Mass/volume] in Serum or Plasma\")\n",
    "\n",
    "unique(measurement_df$standard_concept_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/latex": [],
      "text/markdown": [],
      "text/plain": [
       "character(0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mRows: \u001b[22m\u001b[34m162193\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m28\u001b[39m\n",
      "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m  (8): SexGender, income, education, where_born, military, healthcare, di...\n",
      "\u001b[32mdbl\u001b[39m  (9): person_id, race_unknown, age_today, LGBTQIA, ehr_length, relative_...\n",
      "\u001b[33mlgl\u001b[39m  (8): AIAN, Asian, Black, Mid, Multiple, PI, White, His\n",
      "\u001b[34mdate\u001b[39m (3): date_of_birth, min_date, max_date\n",
      "\n",
      "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
     ]
    }
   ],
   "source": [
    "# This snippet assumes that you run setup first\n",
    "\n",
    "# This code copies a file from your Google Bucket into a dataframe\n",
    "\n",
    "# replace 'test.csv' with the name of the file in your google bucket (don't delete the quotation marks)\n",
    "name_of_file_in_bucket <- 'Demographic_and_ancestry_covariates.csv'\n",
    "\n",
    "########################################################################\n",
    "##\n",
    "################# DON'T CHANGE FROM HERE ###############################\n",
    "##\n",
    "########################################################################\n",
    "\n",
    "# Get the bucket name\n",
    "my_bucket <- Sys.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# Copy the file from current workspace to the bucket\n",
    "system(paste0(\"gsutil cp \", my_bucket, \"/data/\", name_of_file_in_bucket, \" .\"), intern=T)\n",
    "\n",
    "# Load the file into a dataframe\n",
    "demographics  <- read_csv(name_of_file_in_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "SexGender <- data.frame(person_id = demographics$person_id, SexGender = demographics$SexGender, DOB = demographics$date_of_birth)\n",
    "merged_df <- left_join(measurement_df, SexGender, by = \"person_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use snippet 'add_age_to_demographics' to calculate the age of people in your demographics.\n",
    "# It assumes the 'Setup' snippet has been executed.\n",
    "# It also assumes that you got your demographics dataframe from Dataset Builder\n",
    "\n",
    "# Note: This snippet calculates current age and does not take into account whether the person is already dead\n",
    "\n",
    "\n",
    "## -----[ CHANGE THE DATAFRAME NAME(S) `YOUR_DATASET_NAME_person_df` TO MATCH YOURS FROM DATASET BUILDER] -----\n",
    "merged_df <- merged_df %>%\n",
    "                mutate_if(is.list, as.character) %>%\n",
    "                mutate(\n",
    "                    age = year(merged_df$measurement_datetime) - year(merged_df$DOB) - \n",
    "                          ifelse(month(merged_df$measurement_datetime) < month(merged_df$DOB), 1, 0)\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df <- merged_df %>% \n",
    "  mutate(eGFR_2021 = case_when(SexGender == \"Cis_male\" ~ 142 * (pmin(value_as_number/0.9, 1)^-0.302) * (pmax(value_as_number/0.9, 1)^-1.200) * (0.9938^as.numeric(age)), # Male\n",
    "                               SexGender == \"Cis_female\" ~ 142 * (pmin(value_as_number/0.7, 1)^-0.241) * (pmax(value_as_number/0.7, 1)^-1.200) * (0.9938^as.numeric(age)) * 1.012, # Female\n",
    "                               SexGender == \"Non-cis\" ~ 142 * (pmin(value_as_number/0.8, 1)^-0.2715) * (pmax(value_as_number/0.8, 1)^-1.200) * (0.9938^as.numeric(age)) * 1.006))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "4214898"
      ],
      "text/latex": [
       "4214898"
      ],
      "text/markdown": [
       "4214898"
      ],
      "text/plain": [
       "[1] 4214898"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "merged_df2 <- merged_df |> select(1:6, 30)\n",
    "nrow(merged_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df2<-drop_na(merged_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_recent_measurements <- merged_df2 %>%\n",
    "  group_by(person_id) %>%\n",
    "  slice_max(order_by = measurement_datetime, n = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The data will be written to gs://fc-secure-672eeb92-4859-4ed9-9f59-d4349f3534a0/bq_exports/micah_hysong@researchallofus.org/20250825/condition_66443155/condition_66443155_*.csv. Use this path when reading the data into your notebooks in the future.\n",
      "\n",
      "Loading gs://fc-secure-672eeb92-4859-4ed9-9f59-d4349f3534a0/bq_exports/micah_hysong@researchallofus.org/20250825/condition_66443155/condition_66443155_000000000000.csv.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'Severe sepsis'</li><li>'Sepsis due to Serratia'</li><li>'Gonococcemia'</li><li>'Sepsis due to Escherichia coli'</li><li>'Acute meningococcemia'</li><li>'Traumatic shock'</li><li>'Sepsis due to Streptococcus'</li><li>'Sepsis due to Enterobacter'</li><li>'Acute kidney injury due to sepsis'</li><li>'Septic shock'</li><li>'Sepsis due to incomplete miscarriage'</li><li>'Sepsis due to coagulase negative Staphylococcus'</li><li>'Postpartum acute renal failure'</li><li>'Sepsis due to anaerobic bacteria'</li><li>'Hypovolemic shock'</li><li>'Obstetric shock with postnatal problem'</li><li>'Sepsis due to Bacillus anthracis'</li><li>'Shock due to anesthesia'</li><li>'Obstetric shock - delivered'</li><li>'Sepsis due to methicillin resistant Staphylococcus aureus'</li><li>'Sepsis due to Candida'</li><li>'Puerperal pelvic sepsis'</li><li>'Acute kidney failure stage 3'</li><li>'Sepsis following molar AND/OR ectopic pregnancy'</li><li>'Sepsis due to Gram negative bacteria'</li><li>'Sepsis due to methicillin-sensitive Staphylococcus aureus'</li><li>'Sepsis due to Salmonella'</li><li>'Puerperal sepsis'</li><li>'Pyemia'</li><li>'Crush syndrome'</li><li>'Sepsis due to Actinomyces'</li><li>'Hemorrhagic shock'</li><li>'Acute nontraumatic kidney injury'</li><li>'Obstetric shock - delivered with postnatal problem'</li><li>'Gram positive sepsis'</li><li>'Hypovolemia'</li><li>'Acute renal failure due to acute cortical necrosis'</li><li>'Sepsis due to Staphylococcus'</li><li>'Sepsis caused by methicillin susceptible Staphylococcus aureus'</li><li>'Sepsis due to Erysipelothrix'</li><li>'Shock following molar AND/OR ectopic pregnancy'</li><li>'Sepsis due to Pseudomonas'</li><li>'Post-delivery acute renal failure with postnatal problem'</li><li>'Postoperative hypovolemic shock'</li><li>'Sepsis due to urinary tract infection'</li><li>'Acute kidney injury due to circulatory failure'</li><li>'Septicemic plague'</li><li>'Sepsis due to Haemophilus influenzae'</li><li>'Sepsis due to Staphylococcus aureus'</li><li>'Sepsis caused by Enterococcus'</li><li>'Cardiogenic shock'</li><li>'Sepsis due to Listeria monocytogenes'</li><li>'Acute renal papillary necrosis with renal failure'</li><li>'Acute-on-chronic renal failure'</li><li>'Sepsis due to disease caused by Severe acute respiratory syndrome coronavirus 2'</li><li>'Hepatorenal syndrome due to a procedure'</li><li>'Hepatorenal syndrome'</li><li>'Postoperative shock'</li><li>'Sepsis due to Streptococcus pyogenes'</li><li>'Sepsis due to Streptococcus pneumoniae'</li><li>'Miscarriage with sepsis'</li><li>'Acute renal failure syndrome'</li><li>'Sepsis without septic shock'</li><li>'Sepsis due to Streptococcus group D'</li><li>'Sepsis due to Streptococcus agalactiae'</li><li>'Prerenal renal failure'</li><li>'Anaphylactic shock'</li><li>'Acute renal failure caused by contrast agent'</li><li>'Sepsis'</li><li>'Postoperative septic shock'</li><li>'Toxic shock syndrome'</li><li>'Puerperal sepsis with postnatal complication'</li><li>'Bacterial sepsis'</li><li>'Shock during AND/OR following labor AND/OR delivery'</li><li>'Streptococcal toxic shock syndrome'</li><li>'Shock'</li><li>'Sepsis without acute organ dysfunction'</li><li>'Meningococcemia'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'Severe sepsis'\n",
       "\\item 'Sepsis due to Serratia'\n",
       "\\item 'Gonococcemia'\n",
       "\\item 'Sepsis due to Escherichia coli'\n",
       "\\item 'Acute meningococcemia'\n",
       "\\item 'Traumatic shock'\n",
       "\\item 'Sepsis due to Streptococcus'\n",
       "\\item 'Sepsis due to Enterobacter'\n",
       "\\item 'Acute kidney injury due to sepsis'\n",
       "\\item 'Septic shock'\n",
       "\\item 'Sepsis due to incomplete miscarriage'\n",
       "\\item 'Sepsis due to coagulase negative Staphylococcus'\n",
       "\\item 'Postpartum acute renal failure'\n",
       "\\item 'Sepsis due to anaerobic bacteria'\n",
       "\\item 'Hypovolemic shock'\n",
       "\\item 'Obstetric shock with postnatal problem'\n",
       "\\item 'Sepsis due to Bacillus anthracis'\n",
       "\\item 'Shock due to anesthesia'\n",
       "\\item 'Obstetric shock - delivered'\n",
       "\\item 'Sepsis due to methicillin resistant Staphylococcus aureus'\n",
       "\\item 'Sepsis due to Candida'\n",
       "\\item 'Puerperal pelvic sepsis'\n",
       "\\item 'Acute kidney failure stage 3'\n",
       "\\item 'Sepsis following molar AND/OR ectopic pregnancy'\n",
       "\\item 'Sepsis due to Gram negative bacteria'\n",
       "\\item 'Sepsis due to methicillin-sensitive Staphylococcus aureus'\n",
       "\\item 'Sepsis due to Salmonella'\n",
       "\\item 'Puerperal sepsis'\n",
       "\\item 'Pyemia'\n",
       "\\item 'Crush syndrome'\n",
       "\\item 'Sepsis due to Actinomyces'\n",
       "\\item 'Hemorrhagic shock'\n",
       "\\item 'Acute nontraumatic kidney injury'\n",
       "\\item 'Obstetric shock - delivered with postnatal problem'\n",
       "\\item 'Gram positive sepsis'\n",
       "\\item 'Hypovolemia'\n",
       "\\item 'Acute renal failure due to acute cortical necrosis'\n",
       "\\item 'Sepsis due to Staphylococcus'\n",
       "\\item 'Sepsis caused by methicillin susceptible Staphylococcus aureus'\n",
       "\\item 'Sepsis due to Erysipelothrix'\n",
       "\\item 'Shock following molar AND/OR ectopic pregnancy'\n",
       "\\item 'Sepsis due to Pseudomonas'\n",
       "\\item 'Post-delivery acute renal failure with postnatal problem'\n",
       "\\item 'Postoperative hypovolemic shock'\n",
       "\\item 'Sepsis due to urinary tract infection'\n",
       "\\item 'Acute kidney injury due to circulatory failure'\n",
       "\\item 'Septicemic plague'\n",
       "\\item 'Sepsis due to Haemophilus influenzae'\n",
       "\\item 'Sepsis due to Staphylococcus aureus'\n",
       "\\item 'Sepsis caused by Enterococcus'\n",
       "\\item 'Cardiogenic shock'\n",
       "\\item 'Sepsis due to Listeria monocytogenes'\n",
       "\\item 'Acute renal papillary necrosis with renal failure'\n",
       "\\item 'Acute-on-chronic renal failure'\n",
       "\\item 'Sepsis due to disease caused by Severe acute respiratory syndrome coronavirus 2'\n",
       "\\item 'Hepatorenal syndrome due to a procedure'\n",
       "\\item 'Hepatorenal syndrome'\n",
       "\\item 'Postoperative shock'\n",
       "\\item 'Sepsis due to Streptococcus pyogenes'\n",
       "\\item 'Sepsis due to Streptococcus pneumoniae'\n",
       "\\item 'Miscarriage with sepsis'\n",
       "\\item 'Acute renal failure syndrome'\n",
       "\\item 'Sepsis without septic shock'\n",
       "\\item 'Sepsis due to Streptococcus group D'\n",
       "\\item 'Sepsis due to Streptococcus agalactiae'\n",
       "\\item 'Prerenal renal failure'\n",
       "\\item 'Anaphylactic shock'\n",
       "\\item 'Acute renal failure caused by contrast agent'\n",
       "\\item 'Sepsis'\n",
       "\\item 'Postoperative septic shock'\n",
       "\\item 'Toxic shock syndrome'\n",
       "\\item 'Puerperal sepsis with postnatal complication'\n",
       "\\item 'Bacterial sepsis'\n",
       "\\item 'Shock during AND/OR following labor AND/OR delivery'\n",
       "\\item 'Streptococcal toxic shock syndrome'\n",
       "\\item 'Shock'\n",
       "\\item 'Sepsis without acute organ dysfunction'\n",
       "\\item 'Meningococcemia'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'Severe sepsis'\n",
       "2. 'Sepsis due to Serratia'\n",
       "3. 'Gonococcemia'\n",
       "4. 'Sepsis due to Escherichia coli'\n",
       "5. 'Acute meningococcemia'\n",
       "6. 'Traumatic shock'\n",
       "7. 'Sepsis due to Streptococcus'\n",
       "8. 'Sepsis due to Enterobacter'\n",
       "9. 'Acute kidney injury due to sepsis'\n",
       "10. 'Septic shock'\n",
       "11. 'Sepsis due to incomplete miscarriage'\n",
       "12. 'Sepsis due to coagulase negative Staphylococcus'\n",
       "13. 'Postpartum acute renal failure'\n",
       "14. 'Sepsis due to anaerobic bacteria'\n",
       "15. 'Hypovolemic shock'\n",
       "16. 'Obstetric shock with postnatal problem'\n",
       "17. 'Sepsis due to Bacillus anthracis'\n",
       "18. 'Shock due to anesthesia'\n",
       "19. 'Obstetric shock - delivered'\n",
       "20. 'Sepsis due to methicillin resistant Staphylococcus aureus'\n",
       "21. 'Sepsis due to Candida'\n",
       "22. 'Puerperal pelvic sepsis'\n",
       "23. 'Acute kidney failure stage 3'\n",
       "24. 'Sepsis following molar AND/OR ectopic pregnancy'\n",
       "25. 'Sepsis due to Gram negative bacteria'\n",
       "26. 'Sepsis due to methicillin-sensitive Staphylococcus aureus'\n",
       "27. 'Sepsis due to Salmonella'\n",
       "28. 'Puerperal sepsis'\n",
       "29. 'Pyemia'\n",
       "30. 'Crush syndrome'\n",
       "31. 'Sepsis due to Actinomyces'\n",
       "32. 'Hemorrhagic shock'\n",
       "33. 'Acute nontraumatic kidney injury'\n",
       "34. 'Obstetric shock - delivered with postnatal problem'\n",
       "35. 'Gram positive sepsis'\n",
       "36. 'Hypovolemia'\n",
       "37. 'Acute renal failure due to acute cortical necrosis'\n",
       "38. 'Sepsis due to Staphylococcus'\n",
       "39. 'Sepsis caused by methicillin susceptible Staphylococcus aureus'\n",
       "40. 'Sepsis due to Erysipelothrix'\n",
       "41. 'Shock following molar AND/OR ectopic pregnancy'\n",
       "42. 'Sepsis due to Pseudomonas'\n",
       "43. 'Post-delivery acute renal failure with postnatal problem'\n",
       "44. 'Postoperative hypovolemic shock'\n",
       "45. 'Sepsis due to urinary tract infection'\n",
       "46. 'Acute kidney injury due to circulatory failure'\n",
       "47. 'Septicemic plague'\n",
       "48. 'Sepsis due to Haemophilus influenzae'\n",
       "49. 'Sepsis due to Staphylococcus aureus'\n",
       "50. 'Sepsis caused by Enterococcus'\n",
       "51. 'Cardiogenic shock'\n",
       "52. 'Sepsis due to Listeria monocytogenes'\n",
       "53. 'Acute renal papillary necrosis with renal failure'\n",
       "54. 'Acute-on-chronic renal failure'\n",
       "55. 'Sepsis due to disease caused by Severe acute respiratory syndrome coronavirus 2'\n",
       "56. 'Hepatorenal syndrome due to a procedure'\n",
       "57. 'Hepatorenal syndrome'\n",
       "58. 'Postoperative shock'\n",
       "59. 'Sepsis due to Streptococcus pyogenes'\n",
       "60. 'Sepsis due to Streptococcus pneumoniae'\n",
       "61. 'Miscarriage with sepsis'\n",
       "62. 'Acute renal failure syndrome'\n",
       "63. 'Sepsis without septic shock'\n",
       "64. 'Sepsis due to Streptococcus group D'\n",
       "65. 'Sepsis due to Streptococcus agalactiae'\n",
       "66. 'Prerenal renal failure'\n",
       "67. 'Anaphylactic shock'\n",
       "68. 'Acute renal failure caused by contrast agent'\n",
       "69. 'Sepsis'\n",
       "70. 'Postoperative septic shock'\n",
       "71. 'Toxic shock syndrome'\n",
       "72. 'Puerperal sepsis with postnatal complication'\n",
       "73. 'Bacterial sepsis'\n",
       "74. 'Shock during AND/OR following labor AND/OR delivery'\n",
       "75. 'Streptococcal toxic shock syndrome'\n",
       "76. 'Shock'\n",
       "77. 'Sepsis without acute organ dysfunction'\n",
       "78. 'Meningococcemia'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"Severe sepsis\"                                                                  \n",
       " [2] \"Sepsis due to Serratia\"                                                         \n",
       " [3] \"Gonococcemia\"                                                                   \n",
       " [4] \"Sepsis due to Escherichia coli\"                                                 \n",
       " [5] \"Acute meningococcemia\"                                                          \n",
       " [6] \"Traumatic shock\"                                                                \n",
       " [7] \"Sepsis due to Streptococcus\"                                                    \n",
       " [8] \"Sepsis due to Enterobacter\"                                                     \n",
       " [9] \"Acute kidney injury due to sepsis\"                                              \n",
       "[10] \"Septic shock\"                                                                   \n",
       "[11] \"Sepsis due to incomplete miscarriage\"                                           \n",
       "[12] \"Sepsis due to coagulase negative Staphylococcus\"                                \n",
       "[13] \"Postpartum acute renal failure\"                                                 \n",
       "[14] \"Sepsis due to anaerobic bacteria\"                                               \n",
       "[15] \"Hypovolemic shock\"                                                              \n",
       "[16] \"Obstetric shock with postnatal problem\"                                         \n",
       "[17] \"Sepsis due to Bacillus anthracis\"                                               \n",
       "[18] \"Shock due to anesthesia\"                                                        \n",
       "[19] \"Obstetric shock - delivered\"                                                    \n",
       "[20] \"Sepsis due to methicillin resistant Staphylococcus aureus\"                      \n",
       "[21] \"Sepsis due to Candida\"                                                          \n",
       "[22] \"Puerperal pelvic sepsis\"                                                        \n",
       "[23] \"Acute kidney failure stage 3\"                                                   \n",
       "[24] \"Sepsis following molar AND/OR ectopic pregnancy\"                                \n",
       "[25] \"Sepsis due to Gram negative bacteria\"                                           \n",
       "[26] \"Sepsis due to methicillin-sensitive Staphylococcus aureus\"                      \n",
       "[27] \"Sepsis due to Salmonella\"                                                       \n",
       "[28] \"Puerperal sepsis\"                                                               \n",
       "[29] \"Pyemia\"                                                                         \n",
       "[30] \"Crush syndrome\"                                                                 \n",
       "[31] \"Sepsis due to Actinomyces\"                                                      \n",
       "[32] \"Hemorrhagic shock\"                                                              \n",
       "[33] \"Acute nontraumatic kidney injury\"                                               \n",
       "[34] \"Obstetric shock - delivered with postnatal problem\"                             \n",
       "[35] \"Gram positive sepsis\"                                                           \n",
       "[36] \"Hypovolemia\"                                                                    \n",
       "[37] \"Acute renal failure due to acute cortical necrosis\"                             \n",
       "[38] \"Sepsis due to Staphylococcus\"                                                   \n",
       "[39] \"Sepsis caused by methicillin susceptible Staphylococcus aureus\"                 \n",
       "[40] \"Sepsis due to Erysipelothrix\"                                                   \n",
       "[41] \"Shock following molar AND/OR ectopic pregnancy\"                                 \n",
       "[42] \"Sepsis due to Pseudomonas\"                                                      \n",
       "[43] \"Post-delivery acute renal failure with postnatal problem\"                       \n",
       "[44] \"Postoperative hypovolemic shock\"                                                \n",
       "[45] \"Sepsis due to urinary tract infection\"                                          \n",
       "[46] \"Acute kidney injury due to circulatory failure\"                                 \n",
       "[47] \"Septicemic plague\"                                                              \n",
       "[48] \"Sepsis due to Haemophilus influenzae\"                                           \n",
       "[49] \"Sepsis due to Staphylococcus aureus\"                                            \n",
       "[50] \"Sepsis caused by Enterococcus\"                                                  \n",
       "[51] \"Cardiogenic shock\"                                                              \n",
       "[52] \"Sepsis due to Listeria monocytogenes\"                                           \n",
       "[53] \"Acute renal papillary necrosis with renal failure\"                              \n",
       "[54] \"Acute-on-chronic renal failure\"                                                 \n",
       "[55] \"Sepsis due to disease caused by Severe acute respiratory syndrome coronavirus 2\"\n",
       "[56] \"Hepatorenal syndrome due to a procedure\"                                        \n",
       "[57] \"Hepatorenal syndrome\"                                                           \n",
       "[58] \"Postoperative shock\"                                                            \n",
       "[59] \"Sepsis due to Streptococcus pyogenes\"                                           \n",
       "[60] \"Sepsis due to Streptococcus pneumoniae\"                                         \n",
       "[61] \"Miscarriage with sepsis\"                                                        \n",
       "[62] \"Acute renal failure syndrome\"                                                   \n",
       "[63] \"Sepsis without septic shock\"                                                    \n",
       "[64] \"Sepsis due to Streptococcus group D\"                                            \n",
       "[65] \"Sepsis due to Streptococcus agalactiae\"                                         \n",
       "[66] \"Prerenal renal failure\"                                                         \n",
       "[67] \"Anaphylactic shock\"                                                             \n",
       "[68] \"Acute renal failure caused by contrast agent\"                                   \n",
       "[69] \"Sepsis\"                                                                         \n",
       "[70] \"Postoperative septic shock\"                                                     \n",
       "[71] \"Toxic shock syndrome\"                                                           \n",
       "[72] \"Puerperal sepsis with postnatal complication\"                                   \n",
       "[73] \"Bacterial sepsis\"                                                               \n",
       "[74] \"Shock during AND/OR following labor AND/OR delivery\"                            \n",
       "[75] \"Streptococcal toxic shock syndrome\"                                             \n",
       "[76] \"Shock\"                                                                          \n",
       "[77] \"Sepsis without acute organ dysfunction\"                                         \n",
       "[78] \"Meningococcemia\"                                                                "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(tidyverse)\n",
    "library(bigrquery)\n",
    "\n",
    "# This query represents dataset \"egfr_disruptors\" for domain \"condition\" and was generated for All of Us Controlled Tier Dataset v7\n",
    "dataset_66443155_condition_sql <- paste(\"\n",
    "    SELECT\n",
    "        c_occurrence.person_id,\n",
    "        c_occurrence.condition_concept_id,\n",
    "        c_standard_concept.concept_name as standard_concept_name,\n",
    "        c_standard_concept.concept_code as standard_concept_code,\n",
    "        c_standard_concept.vocabulary_id as standard_vocabulary,\n",
    "        c_occurrence.condition_start_datetime \n",
    "    FROM\n",
    "        ( SELECT\n",
    "            * \n",
    "        FROM\n",
    "            `condition_occurrence` c_occurrence \n",
    "        WHERE\n",
    "            (\n",
    "                condition_concept_id IN (SELECT\n",
    "                    DISTINCT c.concept_id \n",
    "                FROM\n",
    "                    `cb_criteria` c \n",
    "                JOIN\n",
    "                    (SELECT\n",
    "                        CAST(cr.id as string) AS id       \n",
    "                    FROM\n",
    "                        `cb_criteria` cr       \n",
    "                    WHERE\n",
    "                        concept_id IN (132797, 197320, 201965, 37311320, 45770903)       \n",
    "                        AND full_text LIKE '%_rank1]%'      ) a \n",
    "                        ON (c.path LIKE CONCAT('%.', a.id, '.%') \n",
    "                        OR c.path LIKE CONCAT('%.', a.id) \n",
    "                        OR c.path LIKE CONCAT(a.id, '.%') \n",
    "                        OR c.path = a.id) \n",
    "                WHERE\n",
    "                    is_standard = 1 \n",
    "                    AND is_selectable = 1)\n",
    "            )  \n",
    "            AND (\n",
    "                c_occurrence.PERSON_ID IN (SELECT\n",
    "                    distinct person_id  \n",
    "                FROM\n",
    "                    `cb_search_person` cb_search_person  \n",
    "                WHERE\n",
    "                    cb_search_person.person_id IN (SELECT\n",
    "                        person_id \n",
    "                    FROM\n",
    "                        `cb_search_person` p \n",
    "                    WHERE\n",
    "                        has_whole_genome_variant = 1 ) \n",
    "                    AND cb_search_person.person_id IN (SELECT\n",
    "                        person_id \n",
    "                    FROM\n",
    "                        `cb_search_person` p \n",
    "                    WHERE\n",
    "                        has_ehr_data = 1 ) )\n",
    "            )) c_occurrence \n",
    "    LEFT JOIN\n",
    "        `concept` c_standard_concept \n",
    "            ON c_occurrence.condition_concept_id = c_standard_concept.concept_id\", sep=\"\")\n",
    "\n",
    "# Formulate a Cloud Storage destination path for the data exported from BigQuery.\n",
    "# NOTE: By default data exported multiple times on the same day will overwrite older copies.\n",
    "#       But data exported on a different days will write to a new location so that historical\n",
    "#       copies can be kept as the dataset definition is changed.\n",
    "condition_66443155_path <- file.path(\n",
    "  Sys.getenv(\"WORKSPACE_BUCKET\"),\n",
    "  \"bq_exports\",\n",
    "  Sys.getenv(\"OWNER_EMAIL\"),\n",
    "  strftime(lubridate::now(), \"%Y%m%d\"),  # Comment out this line if you want the export to always overwrite.\n",
    "  \"condition_66443155\",\n",
    "  \"condition_66443155_*.csv\")\n",
    "message(str_glue('The data will be written to {condition_66443155_path}. Use this path when reading ',\n",
    "                 'the data into your notebooks in the future.'))\n",
    "\n",
    "# Perform the query and export the dataset to Cloud Storage as CSV files.\n",
    "# NOTE: You only need to run `bq_table_save` once. After that, you can\n",
    "#       just read data from the CSVs in Cloud Storage.\n",
    "bq_table_save(\n",
    "  bq_dataset_query(Sys.getenv(\"WORKSPACE_CDR\"), dataset_66443155_condition_sql, billing = Sys.getenv(\"GOOGLE_PROJECT\")),\n",
    "  condition_66443155_path,\n",
    "  destination_format = \"CSV\")\n",
    "\n",
    "\n",
    "# Read the data directly from Cloud Storage into memory.\n",
    "# NOTE: Alternatively you can `gsutil -m cp {condition_66443155_path}` to copy these files\n",
    "#       to the Jupyter disk.\n",
    "read_bq_export_from_workspace_bucket <- function(export_path) {\n",
    "  col_types <- cols(standard_concept_name = col_character(), standard_concept_code = col_character(), standard_vocabulary = col_character())\n",
    "  bind_rows(\n",
    "    map(system2('gsutil', args = c('ls', export_path), stdout = TRUE, stderr = TRUE),\n",
    "        function(csv) {\n",
    "          message(str_glue('Loading {csv}.'))\n",
    "          chunk <- read_csv(pipe(str_glue('gsutil cat {csv}')), col_types = col_types, show_col_types = FALSE)\n",
    "          if (is.null(col_types)) {\n",
    "            col_types <- spec(chunk)\n",
    "          }\n",
    "          chunk\n",
    "        }))\n",
    "}\n",
    "egfr_disruptors_df <- read_bq_export_from_workspace_bucket(condition_66443155_path)\n",
    "\n",
    "unique(egfr_disruptors_df$standard_concept_name)\n",
    "\n",
    "#Remove inappropriate code\n",
    "egfr_disruptors_df<-egfr_disruptors_df[egfr_disruptors_df$standard_concept_code!=140031000119103,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove eGFR that co-occur with disruptors\n",
    "\n",
    "# Calculate the date range for filtering\n",
    "most_recent_measurements$measurement_datetime <- as.POSIXct(most_recent_measurements$measurement_datetime)\n",
    "egfr_disruptors_df$condition_start_datetime <- as.POSIXct(egfr_disruptors_df$condition_start_datetime)\n",
    "\n",
    "most_recent_measurements <- most_recent_measurements %>%\n",
    "  mutate(\n",
    "    lower_bound = measurement_datetime - months(1),\n",
    "    upper_bound = measurement_datetime + months(1)\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a cross join and filter\n",
    "rows_to_remove <- egfr_disruptors_df %>%\n",
    "  inner_join(most_recent_measurements, by = \"person_id\", relationship = \"many-to-many\") %>%\n",
    "  filter(condition_start_datetime >= lower_bound & condition_start_datetime <= upper_bound) %>%\n",
    "  select(person_id, measurement_datetime) %>%\n",
    "  distinct()\n",
    "\n",
    "most_recent_measurements_cleaned <- most_recent_measurements %>%\n",
    "  anti_join(rows_to_remove, by = c(\"person_id\", \"measurement_datetime\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "12644"
      ],
      "text/latex": [
       "12644"
      ],
      "text/markdown": [
       "12644"
      ],
      "text/plain": [
       "[1] 12644"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "potential_cases<-most_recent_measurements_cleaned[most_recent_measurements_cleaned$eGFR_2021<60, ]\n",
    "nrow(potential_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "11355"
      ],
      "text/latex": [
       "11355"
      ],
      "text/markdown": [
       "11355"
      ],
      "text/plain": [
       "[1] 11355"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "potential_cases_list<-setdiff(potential_cases$person_id, dialysis$person_id)\n",
    "potential_cases_list<-setdiff(potential_cases_list, kidney_transplant)\n",
    "potential_cases <- potential_cases[potential_cases$person_id %in% potential_cases_list, ]\n",
    "nrow(potential_cases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now check if they have another low eGFR 3 months prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the most recent datetime for each person_id\n",
    "most_recent_measurements_list <- merged_df2 %>%\n",
    "  group_by(person_id) %>%\n",
    "  summarize(most_recent_datetime = max(measurement_datetime, na.rm = TRUE), .groups = 'drop')\n",
    "\n",
    "# Exclude rows with the most recent measurement_datetime for each person_id\n",
    "other_measurements <- merged_df2 %>%\n",
    "  left_join(most_recent_measurements_list, by = \"person_id\") %>%\n",
    "  filter(measurement_datetime != most_recent_datetime) %>%\n",
    "  select(-most_recent_datetime)\n",
    "\n",
    "#Filter down to only our potential cases\n",
    "other_measurements <- other_measurements[other_measurements$person_id %in% potential_cases_list, ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_recent_measurements <- most_recent_measurements %>%\n",
    "  mutate(\n",
    "    three_months_prior = measurement_datetime - months(3),\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_measurements <- other_measurements |> select(1,6,7)\n",
    "names(other_measurements) <- c(\"person_id\", \"previous_datetime\", \"previous_eGFR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a cross join and filter\n",
    "cases_definition3a <- other_measurements %>%\n",
    "  inner_join(most_recent_measurements, by = \"person_id\", relationship = \"many-to-many\") %>%\n",
    "  filter(previous_datetime <= three_months_prior) %>%\n",
    "  filter(previous_eGFR < 60) %>%\n",
    "  select(person_id) %>%\n",
    "  distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "9400"
      ],
      "text/latex": [
       "9400"
      ],
      "text/markdown": [
       "9400"
      ],
      "text/plain": [
       "[1] 9400"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nrow(cases_definition3a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now check for EHR code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The data will be written to gs://fc-secure-672eeb92-4859-4ed9-9f59-d4349f3534a0/bq_exports/micah_hysong@researchallofus.org/20250825/condition_82100016/condition_82100016_*.csv. Use this path when reading the data into your notebooks in the future.\n",
      "\n",
      "Loading gs://fc-secure-672eeb92-4859-4ed9-9f59-d4349f3534a0/bq_exports/micah_hysong@researchallofus.org/20250825/condition_82100016/condition_82100016_000000000000.csv.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(tidyverse)\n",
    "library(bigrquery)\n",
    "\n",
    "# This query represents dataset \"kidney_disease\" for domain \"condition\" and was generated for All of Us Controlled Tier Dataset v7\n",
    "dataset_82100016_condition_sql <- paste(\"\n",
    "    SELECT\n",
    "        c_occurrence.person_id,\n",
    "        c_occurrence.condition_concept_id,\n",
    "        c_standard_concept.concept_name as standard_concept_name,\n",
    "        c_standard_concept.concept_code as standard_concept_code,\n",
    "        c_standard_concept.vocabulary_id as standard_vocabulary \n",
    "    FROM\n",
    "        ( SELECT\n",
    "            * \n",
    "        FROM\n",
    "            `condition_occurrence` c_occurrence \n",
    "        WHERE\n",
    "            (\n",
    "                condition_concept_id IN (SELECT\n",
    "                    DISTINCT c.concept_id \n",
    "                FROM\n",
    "                    `cb_criteria` c \n",
    "                JOIN\n",
    "                    (SELECT\n",
    "                        CAST(cr.id as string) AS id       \n",
    "                    FROM\n",
    "                        `cb_criteria` cr       \n",
    "                    WHERE\n",
    "                        concept_id IN (198124, 46271022)       \n",
    "                        AND full_text LIKE '%_rank1]%'      ) a \n",
    "                        ON (c.path LIKE CONCAT('%.', a.id, '.%') \n",
    "                        OR c.path LIKE CONCAT('%.', a.id) \n",
    "                        OR c.path LIKE CONCAT(a.id, '.%') \n",
    "                        OR c.path = a.id) \n",
    "                WHERE\n",
    "                    is_standard = 1 \n",
    "                    AND is_selectable = 1)\n",
    "            )  \n",
    "            AND (\n",
    "                c_occurrence.PERSON_ID IN (SELECT\n",
    "                    distinct person_id  \n",
    "                FROM\n",
    "                    `cb_search_person` cb_search_person  \n",
    "                WHERE\n",
    "                    cb_search_person.person_id IN (SELECT\n",
    "                        person_id \n",
    "                    FROM\n",
    "                        `cb_search_person` p \n",
    "                    WHERE\n",
    "                        has_whole_genome_variant = 1 ) \n",
    "                    AND cb_search_person.person_id IN (SELECT\n",
    "                        person_id \n",
    "                    FROM\n",
    "                        `cb_search_person` p \n",
    "                    WHERE\n",
    "                        has_ehr_data = 1 ) )\n",
    "            )) c_occurrence \n",
    "    LEFT JOIN\n",
    "        `concept` c_standard_concept \n",
    "            ON c_occurrence.condition_concept_id = c_standard_concept.concept_id\", sep=\"\")\n",
    "\n",
    "# Formulate a Cloud Storage destination path for the data exported from BigQuery.\n",
    "# NOTE: By default data exported multiple times on the same day will overwrite older copies.\n",
    "#       But data exported on a different days will write to a new location so that historical\n",
    "#       copies can be kept as the dataset definition is changed.\n",
    "condition_82100016_path <- file.path(\n",
    "  Sys.getenv(\"WORKSPACE_BUCKET\"),\n",
    "  \"bq_exports\",\n",
    "  Sys.getenv(\"OWNER_EMAIL\"),\n",
    "  strftime(lubridate::now(), \"%Y%m%d\"),  # Comment out this line if you want the export to always overwrite.\n",
    "  \"condition_82100016\",\n",
    "  \"condition_82100016_*.csv\")\n",
    "message(str_glue('The data will be written to {condition_82100016_path}. Use this path when reading ',\n",
    "                 'the data into your notebooks in the future.'))\n",
    "\n",
    "# Perform the query and export the dataset to Cloud Storage as CSV files.\n",
    "# NOTE: You only need to run `bq_table_save` once. After that, you can\n",
    "#       just read data from the CSVs in Cloud Storage.\n",
    "bq_table_save(\n",
    "  bq_dataset_query(Sys.getenv(\"WORKSPACE_CDR\"), dataset_82100016_condition_sql, billing = Sys.getenv(\"GOOGLE_PROJECT\")),\n",
    "  condition_82100016_path,\n",
    "  destination_format = \"CSV\")\n",
    "\n",
    "\n",
    "# Read the data directly from Cloud Storage into memory.\n",
    "# NOTE: Alternatively you can `gsutil -m cp {condition_82100016_path}` to copy these files\n",
    "#       to the Jupyter disk.\n",
    "read_bq_export_from_workspace_bucket <- function(export_path) {\n",
    "  col_types <- cols(standard_concept_name = col_character(), standard_concept_code = col_character(), standard_vocabulary = col_character())\n",
    "  bind_rows(\n",
    "    map(system2('gsutil', args = c('ls', export_path), stdout = TRUE, stderr = TRUE),\n",
    "        function(csv) {\n",
    "          message(str_glue('Loading {csv}.'))\n",
    "          chunk <- read_csv(pipe(str_glue('gsutil cat {csv}')), col_types = col_types, show_col_types = FALSE)\n",
    "          if (is.null(col_types)) {\n",
    "            col_types <- spec(chunk)\n",
    "          }\n",
    "          chunk\n",
    "        }))\n",
    "}\n",
    "kidney_disease_df <- read_bq_export_from_workspace_bucket(condition_82100016_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "8232"
      ],
      "text/latex": [
       "8232"
      ],
      "text/markdown": [
       "8232"
      ],
      "text/plain": [
       "[1] 8232"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cases_definition3b<-intersect(potential_cases$person_id, kidney_disease_df$person_id)\n",
    "length(cases_definition3b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "14259"
      ],
      "text/latex": [
       "14259"
      ],
      "text/markdown": [
       "14259"
      ],
      "text/plain": [
       "[1] 14259"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cases<-unique(c(case_definition_1, case_definition_2$person_id, cases_definition3a$person_id, cases_definition3b ))\n",
    "length(cases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "49984"
      ],
      "text/latex": [
       "49984"
      ],
      "text/markdown": [
       "49984"
      ],
      "text/plain": [
       "[1] 49984"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "most_recent_measure_not_ckd<-most_recent_measurements_cleaned[most_recent_measurements_cleaned$eGFR_2021>=90,]\n",
    "nrow(most_recent_measure_not_ckd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "39650"
      ],
      "text/latex": [
       "39650"
      ],
      "text/markdown": [
       "39650"
      ],
      "text/plain": [
       "[1] 39650"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "controls0<-setdiff(most_recent_measure_not_ckd$person_id, kidney_disease_df$person_id)\n",
    "controls<-setdiff(controls0, cases)\n",
    "length(controls0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "53862"
      ],
      "text/latex": [
       "53862"
      ],
      "text/markdown": [
       "53862"
      ],
      "text/plain": [
       "[1] 53862"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "53862"
      ],
      "text/latex": [
       "53862"
      ],
      "text/markdown": [
       "53862"
      ],
      "text/plain": [
       "[1] 53862"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_cases <- data.frame(\n",
    "  person_id = cases,\n",
    "  status = 1\n",
    ")\n",
    "\n",
    "df_controls <- data.frame(\n",
    "  person_id = controls,\n",
    "  status = 0\n",
    ")\n",
    "\n",
    "final_df <- rbind(df_cases, df_controls)\n",
    "nrow(final_df)\n",
    "n_distinct(final_df$person_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/latex": [],
      "text/markdown": [],
      "text/plain": [
       "character(0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'gs://fc-secure-672eeb92-4859-4ed9-9f59-d4349f3534a0/data/Demographic_and_ancestry_covariates.csv'</li><li>'gs://fc-secure-672eeb92-4859-4ed9-9f59-d4349f3534a0/data/all_demographics.csv'</li><li>'gs://fc-secure-672eeb92-4859-4ed9-9f59-d4349f3534a0/data/eMERGE_CAD_case_control_df.csv'</li><li>'gs://fc-secure-672eeb92-4859-4ed9-9f59-d4349f3534a0/data/eMERGE_CKD_case_control_df.csv'</li><li>'gs://fc-secure-672eeb92-4859-4ed9-9f59-d4349f3534a0/data/eMERGE_afib_case_control_df.csv'</li><li>'gs://fc-secure-672eeb92-4859-4ed9-9f59-d4349f3534a0/data/eMERGE_asthma_case_control_df.csv'</li><li>'gs://fc-secure-672eeb92-4859-4ed9-9f59-d4349f3534a0/data/eMERGE_breast_cancer_case_control_df.csv'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'gs://fc-secure-672eeb92-4859-4ed9-9f59-d4349f3534a0/data/Demographic\\_and\\_ancestry\\_covariates.csv'\n",
       "\\item 'gs://fc-secure-672eeb92-4859-4ed9-9f59-d4349f3534a0/data/all\\_demographics.csv'\n",
       "\\item 'gs://fc-secure-672eeb92-4859-4ed9-9f59-d4349f3534a0/data/eMERGE\\_CAD\\_case\\_control\\_df.csv'\n",
       "\\item 'gs://fc-secure-672eeb92-4859-4ed9-9f59-d4349f3534a0/data/eMERGE\\_CKD\\_case\\_control\\_df.csv'\n",
       "\\item 'gs://fc-secure-672eeb92-4859-4ed9-9f59-d4349f3534a0/data/eMERGE\\_afib\\_case\\_control\\_df.csv'\n",
       "\\item 'gs://fc-secure-672eeb92-4859-4ed9-9f59-d4349f3534a0/data/eMERGE\\_asthma\\_case\\_control\\_df.csv'\n",
       "\\item 'gs://fc-secure-672eeb92-4859-4ed9-9f59-d4349f3534a0/data/eMERGE\\_breast\\_cancer\\_case\\_control\\_df.csv'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'gs://fc-secure-672eeb92-4859-4ed9-9f59-d4349f3534a0/data/Demographic_and_ancestry_covariates.csv'\n",
       "2. 'gs://fc-secure-672eeb92-4859-4ed9-9f59-d4349f3534a0/data/all_demographics.csv'\n",
       "3. 'gs://fc-secure-672eeb92-4859-4ed9-9f59-d4349f3534a0/data/eMERGE_CAD_case_control_df.csv'\n",
       "4. 'gs://fc-secure-672eeb92-4859-4ed9-9f59-d4349f3534a0/data/eMERGE_CKD_case_control_df.csv'\n",
       "5. 'gs://fc-secure-672eeb92-4859-4ed9-9f59-d4349f3534a0/data/eMERGE_afib_case_control_df.csv'\n",
       "6. 'gs://fc-secure-672eeb92-4859-4ed9-9f59-d4349f3534a0/data/eMERGE_asthma_case_control_df.csv'\n",
       "7. 'gs://fc-secure-672eeb92-4859-4ed9-9f59-d4349f3534a0/data/eMERGE_breast_cancer_case_control_df.csv'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"gs://fc-secure-672eeb92-4859-4ed9-9f59-d4349f3534a0/data/Demographic_and_ancestry_covariates.csv\" \n",
       "[2] \"gs://fc-secure-672eeb92-4859-4ed9-9f59-d4349f3534a0/data/all_demographics.csv\"                    \n",
       "[3] \"gs://fc-secure-672eeb92-4859-4ed9-9f59-d4349f3534a0/data/eMERGE_CAD_case_control_df.csv\"          \n",
       "[4] \"gs://fc-secure-672eeb92-4859-4ed9-9f59-d4349f3534a0/data/eMERGE_CKD_case_control_df.csv\"          \n",
       "[5] \"gs://fc-secure-672eeb92-4859-4ed9-9f59-d4349f3534a0/data/eMERGE_afib_case_control_df.csv\"         \n",
       "[6] \"gs://fc-secure-672eeb92-4859-4ed9-9f59-d4349f3534a0/data/eMERGE_asthma_case_control_df.csv\"       \n",
       "[7] \"gs://fc-secure-672eeb92-4859-4ed9-9f59-d4349f3534a0/data/eMERGE_breast_cancer_case_control_df.csv\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This snippet assumes that you run setup first\n",
    "\n",
    "# This code saves your dataframe into a csv file in a \"data\" folder in Google Bucket\n",
    "\n",
    "# Replace df with THE NAME OF YOUR DATAFRAME\n",
    "my_dataframe <- final_df\n",
    "\n",
    "# Replace 'test.csv' with THE NAME of the file you're going to store in the bucket (don't delete the quotation marks)\n",
    "destination_filename <- 'eMERGE_CKD_case_control_df.csv'\n",
    "\n",
    "########################################################################\n",
    "##\n",
    "################# DON'T CHANGE FROM HERE ###############################\n",
    "##\n",
    "########################################################################\n",
    "\n",
    "# store the dataframe in current workspace\n",
    "write_excel_csv(my_dataframe, destination_filename)\n",
    "\n",
    "# Get the bucket name\n",
    "my_bucket <- Sys.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# Copy the file from current workspace to the bucket\n",
    "system(paste0(\"gsutil cp ./\", destination_filename, \" \", my_bucket, \"/data/\"), intern=T)\n",
    "\n",
    "# Check if file is in the bucket\n",
    "system(paste0(\"gsutil ls \", my_bucket, \"/data/*.csv\"), intern=T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.5.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
